--- STDOUT ---
INFO 06-25 15:30:21 [__init__.py:244] Automatically detected platform cuda.
When dataset path is not set, it will default to random dataset
Namespace(backend='vllm', dataset_name='random', dataset=None, dataset_path=None, input_len=1024, output_len=1024, n=1, num_prompts=200, hf_max_batch_size=None, output_json=None, async_engine=False, disable_frontend_multiprocessing=False, disable_detokenize=False, lora_path=None, prefix_len=None, random_range_ratio=None, hf_subset=None, hf_split=None, model='google/gemma-3-27b-it', task='auto', tokenizer='google/gemma-3-27b-it', tokenizer_mode='auto', trust_remote_code=False, dtype='auto', seed=0, hf_config_path=None, allowed_local_media_path='', revision=None, code_revision=None, rope_scaling={}, rope_theta=None, tokenizer_revision=None, max_model_len=2048, quantization='fp8', enforce_eager=False, max_seq_len_to_capture=8192, max_logprobs=20, disable_sliding_window=False, disable_cascade_attn=False, skip_tokenizer_init=False, enable_prompt_embeds=False, served_model_name=None, disable_async_output_proc=False, config_format='auto', hf_token=None, hf_overrides={}, override_neuron_config={}, override_pooler_config=None, logits_processor_pattern=None, generation_config='auto', override_generation_config={}, enable_sleep_mode=False, model_impl='auto', load_format='auto', download_dir=None, model_loader_extra_config={}, ignore_patterns=None, use_tqdm_on_load=True, qlora_adapter_name_or_path=None, pt_load_map_location='cpu', guided_decoding_backend='auto', guided_decoding_disable_fallback=False, guided_decoding_disable_any_whitespace=False, guided_decoding_disable_additional_properties=False, enable_reasoning=None, reasoning_parser='', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=2, data_parallel_size=1, data_parallel_size_local=None, data_parallel_address=None, data_parallel_rpc_port=None, data_parallel_backend='mp', enable_expert_parallel=False, max_parallel_loading_workers=None, ray_workers_use_nsight=False, disable_custom_all_reduce=False, worker_cls='auto', worker_extension_cls='', enable_multimodal_encoder_data_parallel=False, block_size=None, gpu_memory_utilization=0.9, swap_space=4, kv_cache_dtype='auto', num_gpu_blocks_override=None, enable_prefix_caching=None, prefix_caching_hash_algo='builtin', cpu_offload_gb=0, calculate_kv_scales=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config={}, limit_mm_per_prompt={}, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=None, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=None, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', speculative_config=None, show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, max_num_batched_tokens=None, max_num_seqs=None, max_num_partial_prefills=1, max_long_partial_prefills=1, cuda_graph_sizes=[512], long_prefill_token_threshold=0, num_lookahead_slots=0, scheduler_delay_factor=0.0, preemption_mode=None, num_scheduler_steps=1, multi_step_stream_outputs=True, scheduling_policy='fcfs', enable_chunked_prefill=None, disable_chunked_mm_input=False, scheduler_cls='vllm.core.scheduler.Scheduler', disable_hybrid_kv_cache_manager=False, kv_transfer_config=None, kv_events_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":[],"use_inductor":true,"compile_sizes":null,"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":null,"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":null,"local_cache_dir":null}, additional_config={}, use_v2_block_manager=True, disable_log_stats=False, disable_log_requests=False)
INFO 06-25 15:30:30 [config.py:823] This model supports multiple tasks: {'score', 'embed', 'reward', 'classify', 'generate'}. Defaulting to 'generate'.
INFO 06-25 15:30:30 [config.py:1946] Defaulting to use mp for distributed inference
INFO 06-25 15:30:30 [config.py:2195] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 06-25 15:30:32 [core.py:455] Waiting for init message from front-end.
INFO 06-25 15:30:32 [core.py:70] Initializing a V1 LLM engine (v0.9.1) with config: model='google/gemma-3-27b-it', speculative_config=None, tokenizer='google/gemma-3-27b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=google/gemma-3-27b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":512,"local_cache_dir":null}
WARNING 06-25 15:30:32 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 112 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 06-25 15:30:32 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1], buffer_handle=(2, 16777216, 10, 'psm_8ffdbf13'), local_subscribe_addr='ipc:///tmp/89fd7e2d-50e0-463d-894e-47df4780e6a7', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 06-25 15:30:32 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7d85bd352c60>
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:30:32 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_48aae532'), local_subscribe_addr='ipc:///tmp/739ca56a-99a0-4c28-8251-66de564b7b84', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 06-25 15:30:32 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7d87111315b0>
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:30:32 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e4c68e1b'), local_subscribe_addr='ipc:///tmp/ab128376-0feb-4790-9d07-be4faaa1ad1d', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:30:39 [utils.py:1126] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:30:39 [pynccl.py:70] vLLM is using nccl==2.26.2
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:30:39 [utils.py:1126] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:30:39 [pynccl.py:70] vLLM is using nccl==2.26.2
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:09 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /mnt/disks/mlperf-scratch/gpu_p2p_access_cache_for_0,1,2,3,4,5,6,7.json
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:09 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /mnt/disks/mlperf-scratch/gpu_p2p_access_cache_for_0,1,2,3,4,5,6,7.json
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:09 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_9d1c59c1'), local_subscribe_addr='ipc:///tmp/a48108a9-1459-499a-9817-b36c74828dfd', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:09 [parallel_state.py:1065] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:09 [parallel_state.py:1065] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1
[1;36m(VllmWorker rank=0 pid=87800)[0;0m WARNING 06-25 15:31:14 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:14 [gpu_model_runner.py:1595] Starting to load model google/gemma-3-27b-it...
[1;36m(VllmWorker rank=1 pid=87801)[0;0m WARNING 06-25 15:31:14 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:14 [gpu_model_runner.py:1595] Starting to load model google/gemma-3-27b-it...
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:14 [gpu_model_runner.py:1600] Loading model from scratch...
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:14 [cuda.py:246] FlashInfer failed to import for V1 engine on Blackwell (SM 10.0) GPUs; it is recommended to install FlashInfer for better performance.
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:14 [cuda.py:252] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:14 [gpu_model_runner.py:1600] Loading model from scratch...
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:14 [cuda.py:246] FlashInfer failed to import for V1 engine on Blackwell (SM 10.0) GPUs; it is recommended to install FlashInfer for better performance.
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:14 [cuda.py:252] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:15 [weight_utils.py:292] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:15 [weight_utils.py:292] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:22 [default_loader.py:272] Loading weights took 7.30 seconds
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:23 [gpu_model_runner.py:1624] Model loading took 13.9147 GiB and 7.837445 seconds
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:23 [default_loader.py:272] Loading weights took 8.18 seconds
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:23 [gpu_model_runner.py:1624] Model loading took 13.9147 GiB and 8.692618 seconds
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:23 [gpu_model_runner.py:1978] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 64 image items of the maximum feature size.
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:23 [gpu_model_runner.py:1978] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 64 image items of the maximum feature size.
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:40 [backends.py:462] Using cache directory: /mnt/disks/mlperf-scratch/torch_compile_cache/afec0cda80/rank_0_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:40 [backends.py:472] Dynamo bytecode transform time: 14.47 s
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:40 [backends.py:462] Using cache directory: /mnt/disks/mlperf-scratch/torch_compile_cache/afec0cda80/rank_1_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:40 [backends.py:472] Dynamo bytecode transform time: 14.58 s
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:31:44 [backends.py:161] Cache the graph of shape None for later use
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:31:44 [backends.py:161] Cache the graph of shape None for later use
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:32:34 [backends.py:173] Compiling a graph for general shape takes 52.62 s
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:32:34 [backends.py:173] Compiling a graph for general shape takes 53.10 s
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:33:23 [monitor.py:34] torch.compile takes 67.09 s in total
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:33:23 [monitor.py:34] torch.compile takes 67.68 s in total
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:33:24 [gpu_worker.py:227] Available KV cache memory: 134.53 GiB
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:33:24 [gpu_worker.py:227] Available KV cache memory: 134.53 GiB
WARNING 06-25 15:33:24 [kv_cache_utils.py:830] Add 8 padding layers, may waste at most 15.38% KV cache memory
INFO 06-25 15:33:24 [kv_cache_utils.py:870] GPU KV cache size: 503,792 tokens
INFO 06-25 15:33:24 [kv_cache_utils.py:874] Maximum concurrency for 2,048 tokens per request: 244.36x
WARNING 06-25 15:33:24 [kv_cache_utils.py:830] Add 8 padding layers, may waste at most 15.38% KV cache memory
INFO 06-25 15:33:24 [kv_cache_utils.py:870] GPU KV cache size: 503,792 tokens
INFO 06-25 15:33:24 [kv_cache_utils.py:874] Maximum concurrency for 2,048 tokens per request: 244.36x
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:33:46 [custom_all_reduce.py:196] Registering 8308 cuda graph addresses
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:33:47 [custom_all_reduce.py:196] Registering 8308 cuda graph addresses
[1;36m(VllmWorker rank=1 pid=87801)[0;0m INFO 06-25 15:33:47 [gpu_model_runner.py:2048] Graph capturing finished in 22 secs, took 1.21 GiB
[1;36m(VllmWorker rank=0 pid=87800)[0;0m INFO 06-25 15:33:47 [gpu_model_runner.py:2048] Graph capturing finished in 22 secs, took 1.21 GiB
INFO 06-25 15:33:47 [core.py:171] init engine (profile, create kv cache, warmup model) took 143.69 seconds
ERROR 06-25 15:33:59 [dump_input.py:69] Dumping input data
ERROR 06-25 15:33:59 [dump_input.py:71] V1 LLM engine (v0.9.1) with config: model='google/gemma-3-27b-it', speculative_config=None, tokenizer='google/gemma-3-27b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=google/gemma-3-27b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":512,"local_cache_dir":null}, 
ERROR 06-25 15:33:59 [dump_input.py:79] Dumping scheduler output for model execution:
ERROR 06-25 15:33:59 [dump_input.py:80] SchedulerOutput(scheduled_new_reqs=[NewRequestData(req_id=177,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([80137, 80138, 80139, 80140, 80141, 80142, 80143, 80144, 80145, 80146, 80147, 80148, 80149, 80150, 80151, 80152, 80153, 80154, 80155, 80156, 80157, 80158, 80159, 80160, 80161, 80162, 80163, 80164, 80165, 80166, 80167, 80168, 80169, 80170, 80171, 80172, 80173, 80174, 80175, 80176, 80177, 80178, 80179, 80180, 80181, 80182, 80183, 80184, 80185, 80186, 80187, 80188, 80189, 80190, 80191, 80192, 80193, 80194, 80195, 80196, 80197, 80198, 80199, 80200], [80201, 80202, 80203, 80204, 80205, 80206, 80207, 80208, 80209, 80210, 80211, 80212, 80213, 80214, 80215, 80216, 80217, 80218, 80219, 80220, 80221, 80222, 80223, 80224, 80225, 80226, 80227, 80228, 80229, 80230, 80231, 80232, 80233, 80234, 80235, 80236, 80237, 80238, 80239, 80240, 80241, 80242, 80243, 80244, 80245, 80246, 80247, 80248, 80249, 80250, 80251, 80252, 80253, 80254, 80255, 80256, 80257, 80258, 80259, 80260, 80261, 80262, 80263, 80264], [80265, 80266, 80267, 80268, 80269, 80270, 80271, 80272, 80273, 80274, 80275, 80276, 80277, 80278, 80279, 80280, 80281, 80282, 80283, 80284, 80285, 80286, 80287, 80288, 80289, 80290, 80291, 80292, 80293, 80294, 80295, 80296, 80297, 80298, 80299, 80300, 80301, 80302, 80303, 80304, 80305, 80306, 80307, 80308, 80309, 80310, 80311, 80312, 80313, 80314, 80315, 80316, 80317, 80318, 80319, 80320, 80321, 80322, 80323, 80324, 80325, 80326, 80327, 80328], [80329, 80330, 80331, 80332, 80333, 80334, 80335, 80336, 80337, 80338, 80339, 80340, 80341, 80342, 80343, 80344, 80345, 80346, 80347, 80348, 80349, 80350, 80351, 80352, 80353, 80354, 80355, 80356, 80357, 80358, 80359, 80360, 80361, 80362, 80363, 80364, 80365, 80366, 80367, 80368, 80369, 80370, 80371, 80372, 80373, 80374, 80375, 80376, 80377, 80378, 80379, 80380, 80381, 80382, 80383, 80384, 80385, 80386, 80387, 80388, 80389, 80390, 80391, 80392], [80393, 80394, 80395, 80396, 80397, 80398, 80399, 80400, 80401, 80402, 80403, 80404, 80405, 80406, 80407, 80408, 80409, 80410, 80411, 80412, 80413, 80414, 80415, 80416, 80417, 80418, 80419, 80420, 80421, 80422, 80423, 80424, 80425, 80426, 80427, 80428, 80429, 80430, 80431, 80432, 80433, 80434, 80435, 80436, 80437, 80438, 80439, 80440, 80441, 80442, 80443, 80444, 80445, 80446, 80447, 80448, 80449, 80450, 80451, 80452, 80453, 80454, 80455, 80456], [80457, 80458, 80459, 80460, 80461, 80462, 80463, 80464, 80465, 80466, 80467, 80468, 80469, 80470, 80471, 80472, 80473, 80474, 80475, 80476, 80477, 80478, 80479, 80480, 80481, 80482, 80483, 80484, 80485, 80486, 80487, 80488, 80489, 80490, 80491, 80492, 80493, 80494, 80495, 80496, 80497, 80498, 80499, 80500, 80501, 80502, 80503, 80504, 80505, 80506, 80507, 80508, 80509, 80510, 80511, 80512, 80513, 80514, 80515, 80516, 80517, 80518, 80519, 80520], [80521, 80522, 80523, 80524, 80525, 80526, 80527, 80528, 80529, 80530, 80531, 80532, 80533, 80534, 80535, 80536, 80537, 80538, 80539, 80540, 80541, 80542, 80543, 80544, 80545, 80546, 80547, 80548, 80549, 80550, 80551, 80552, 80553, 80554, 80555, 80556, 80557, 80558, 80559, 80560, 80561, 80562, 80563, 80564, 80565, 80566, 80567, 80568, 80569, 80570, 80571, 80572, 80573, 80574, 80575, 80576, 80577, 80578, 80579, 80580, 80581, 80582, 80583, 80584]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=178,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([80585, 80586, 80587, 80588, 80589, 80590, 80591, 80592, 80593, 80594, 80595, 80596, 80597, 80598, 80599, 80600, 80601, 80602, 80603, 80604, 80605, 80606, 80607, 80608, 80609, 80610, 80611, 80612, 80613, 80614, 80615, 80616, 80617, 80618, 80619, 80620, 80621, 80622, 80623, 80624, 80625, 80626, 80627, 80628, 80629, 80630, 80631, 80632, 80633, 80634, 80635, 80636, 80637, 80638, 80639, 80640, 80641, 80642, 80643, 80644, 80645, 80646, 80647, 80648], [80649, 80650, 80651, 80652, 80653, 80654, 80655, 80656, 80657, 80658, 80659, 80660, 80661, 80662, 80663, 80664, 80665, 80666, 80667, 80668, 80669, 80670, 80671, 80672, 80673, 80674, 80675, 80676, 80677, 80678, 80679, 80680, 80681, 80682, 80683, 80684, 80685, 80686, 80687, 80688, 80689, 80690, 80691, 80692, 80693, 80694, 80695, 80696, 80697, 80698, 80699, 80700, 80701, 80702, 80703, 80704, 80705, 80706, 80707, 80708, 80709, 80710, 80711, 80712], [80713, 80714, 80715, 80716, 80717, 80718, 80719, 80720, 80721, 80722, 80723, 80724, 80725, 80726, 80727, 80728, 80729, 80730, 80731, 80732, 80733, 80734, 80735, 80736, 80737, 80738, 80739, 80740, 80741, 80742, 80743, 80744, 80745, 80746, 80747, 80748, 80749, 80750, 80751, 80752, 80753, 80754, 80755, 80756, 80757, 80758, 80759, 80760, 80761, 80762, 80763, 80764, 80765, 80766, 80767, 80768, 80769, 80770, 80771, 80772, 80773, 80774, 80775, 80776], [80777, 80778, 80779, 80780, 80781, 80782, 80783, 80784, 80785, 80786, 80787, 80788, 80789, 80790, 80791, 80792, 80793, 80794, 80795, 80796, 80797, 80798, 80799, 80800, 80801, 80802, 80803, 80804, 80805, 80806, 80807, 80808, 80809, 80810, 80811, 80812, 80813, 80814, 80815, 80816, 80817, 80818, 80819, 80820, 80821, 80822, 80823, 80824, 80825, 80826, 80827, 80828, 80829, 80830, 80831, 80832, 80833, 80834, 80835, 80836, 80837, 80838, 80839, 80840], [80841, 80842, 80843, 80844, 80845, 80846, 80847, 80848, 80849, 80850, 80851, 80852, 80853, 80854, 80855, 80856, 80857, 80858, 80859, 80860, 80861, 80862, 80863, 80864, 80865, 80866, 80867, 80868, 80869, 80870, 80871, 80872, 80873, 80874, 80875, 80876, 80877, 80878, 80879, 80880, 80881, 80882, 80883, 80884, 80885, 80886, 80887, 80888, 80889, 80890, 80891, 80892, 80893, 80894, 80895, 80896, 80897, 80898, 80899, 80900, 80901, 80902, 80903, 80904], [80905, 80906, 80907, 80908, 80909, 80910, 80911, 80912, 80913, 80914, 80915, 80916, 80917, 80918, 80919, 80920, 80921, 80922, 80923, 80924, 80925, 80926, 80927, 80928, 80929, 80930, 80931, 80932, 80933, 80934, 80935, 80936, 80937, 80938, 80939, 80940, 80941, 80942, 80943, 80944, 80945, 80946, 80947, 80948, 80949, 80950, 80951, 80952, 80953, 80954, 80955, 80956, 80957, 80958, 80959, 80960, 80961, 80962, 80963, 80964, 80965, 80966, 80967, 80968], [80969, 80970, 80971, 80972, 80973, 80974, 80975, 80976, 80977, 80978, 80979, 80980, 80981, 80982, 80983, 80984, 80985, 80986, 80987, 80988, 80989, 80990, 80991, 80992, 80993, 80994, 80995, 80996, 80997, 80998, 80999, 81000, 81001, 81002, 81003, 81004, 81005, 81006, 81007, 81008, 81009, 81010, 81011, 81012, 81013, 81014, 81015, 81016, 81017, 81018, 81019, 81020, 81021, 81022, 81023, 81024, 81025, 81026, 81027, 81028, 81029, 81030, 81031, 81032]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=179,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([81033, 81034, 81035, 81036, 81037, 81038, 81039, 81040, 81041, 81042, 81043, 81044, 81045, 81046, 81047, 81048, 81049, 81050, 81051, 81052, 81053, 81054, 81055, 81056, 81057, 81058, 81059, 81060, 81061, 81062, 81063, 81064, 81065, 81066, 81067, 81068, 81069, 81070, 81071, 81072, 81073, 81074, 81075, 81076, 81077, 81078, 81079, 81080, 81081, 81082, 81083, 81084, 81085, 81086, 81087, 81088, 81089, 81090, 81091, 81092, 81093, 81094, 81095, 81096], [81097, 81098, 81099, 81100, 81101, 81102, 81103, 81104, 81105, 81106, 81107, 81108, 81109, 81110, 81111, 81112, 81113, 81114, 81115, 81116, 81117, 81118, 81119, 81120, 81121, 81122, 81123, 81124, 81125, 81126, 81127, 81128, 81129, 81130, 81131, 81132, 81133, 81134, 81135, 81136, 81137, 81138, 81139, 81140, 81141, 81142, 81143, 81144, 81145, 81146, 81147, 81148, 81149, 81150, 81151, 81152, 81153, 81154, 81155, 81156, 81157, 81158, 81159, 81160], [81161, 81162, 81163, 81164, 81165, 81166, 81167, 81168, 81169, 81170, 81171, 81172, 81173, 81174, 81175, 81176, 81177, 81178, 81179, 81180, 81181, 81182, 81183, 81184, 81185, 81186, 81187, 81188, 81189, 81190, 81191, 81192, 81193, 81194, 81195, 81196, 81197, 81198, 81199, 81200, 81201, 81202, 81203, 81204, 81205, 81206, 81207, 81208, 81209, 81210, 81211, 81212, 81213, 81214, 81215, 81216, 81217, 81218, 81219, 81220, 81221, 81222, 81223, 81224], [81225, 81226, 81227, 81228, 81229, 81230, 81231, 81232, 81233, 81234, 81235, 81236, 81237, 81238, 81239, 81240, 81241, 81242, 81243, 81244, 81245, 81246, 81247, 81248, 81249, 81250, 81251, 81252, 81253, 81254, 81255, 81256, 81257, 81258, 81259, 81260, 81261, 81262, 81263, 81264, 81265, 81266, 81267, 81268, 81269, 81270, 81271, 81272, 81273, 81274, 81275, 81276, 81277, 81278, 81279, 81280, 81281, 81282, 81283, 81284, 81285, 81286, 81287, 81288], [81289, 81290, 81291, 81292, 81293, 81294, 81295, 81296, 81297, 81298, 81299, 81300, 81301, 81302, 81303, 81304, 81305, 81306, 81307, 81308, 81309, 81310, 81311, 81312, 81313, 81314, 81315, 81316, 81317, 81318, 81319, 81320, 81321, 81322, 81323, 81324, 81325, 81326, 81327, 81328, 81329, 81330, 81331, 81332, 81333, 81334, 81335, 81336, 81337, 81338, 81339, 81340, 81341, 81342, 81343, 81344, 81345, 81346, 81347, 81348, 81349, 81350, 81351, 81352], [81353, 81354, 81355, 81356, 81357, 81358, 81359, 81360, 81361, 81362, 81363, 81364, 81365, 81366, 81367, 81368, 81369, 81370, 81371, 81372, 81373, 81374, 81375, 81376, 81377, 81378, 81379, 81380, 81381, 81382, 81383, 81384, 81385, 81386, 81387, 81388, 81389, 81390, 81391, 81392, 81393, 81394, 81395, 81396, 81397, 81398, 81399, 81400, 81401, 81402, 81403, 81404, 81405, 81406, 81407, 81408, 81409, 81410, 81411, 81412, 81413, 81414, 81415, 81416], [81417, 81418, 81419, 81420, 81421, 81422, 81423, 81424, 81425, 81426, 81427, 81428, 81429, 81430, 81431, 81432, 81433, 81434, 81435, 81436, 81437, 81438, 81439, 81440, 81441, 81442, 81443, 81444, 81445, 81446, 81447, 81448, 81449, 81450, 81451, 81452, 81453, 81454, 81455, 81456, 81457, 81458, 81459, 81460, 81461, 81462, 81463, 81464, 81465, 81466, 81467, 81468, 81469, 81470, 81471, 81472, 81473, 81474, 81475, 81476, 81477, 81478, 81479, 81480]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=180,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([81481, 81482, 81483, 81484, 81485, 81486, 81487, 81488, 81489, 81490, 81491, 81492, 81493, 81494, 81495, 81496, 81497, 81498, 81499, 81500, 81501, 81502, 81503, 81504, 81505, 81506, 81507, 81508, 81509, 81510, 81511, 81512, 81513, 81514, 81515, 81516, 81517, 81518, 81519, 81520, 81521, 81522, 81523, 81524, 81525, 81526, 81527, 81528, 81529, 81530, 81531, 81532, 81533, 81534, 81535, 81536, 81537, 81538, 81539, 81540, 81541, 81542, 81543, 81544], [81545, 81546, 81547, 81548, 81549, 81550, 81551, 81552, 81553, 81554, 81555, 81556, 81557, 81558, 81559, 81560, 81561, 81562, 81563, 81564, 81565, 81566, 81567, 81568, 81569, 81570, 81571, 81572, 81573, 81574, 81575, 81576, 81577, 81578, 81579, 81580, 81581, 81582, 81583, 81584, 81585, 81586, 81587, 81588, 81589, 81590, 81591, 81592, 81593, 81594, 81595, 81596, 81597, 81598, 81599, 81600, 81601, 81602, 81603, 81604, 81605, 81606, 81607, 81608], [81609, 81610, 81611, 81612, 81613, 81614, 81615, 81616, 81617, 81618, 81619, 81620, 81621, 81622, 81623, 81624, 81625, 81626, 81627, 81628, 81629, 81630, 81631, 81632, 81633, 81634, 81635, 81636, 81637, 81638, 81639, 81640, 81641, 81642, 81643, 81644, 81645, 81646, 81647, 81648, 81649, 81650, 81651, 81652, 81653, 81654, 81655, 81656, 81657, 81658, 81659, 81660, 81661, 81662, 81663, 81664, 81665, 81666, 81667, 81668, 81669, 81670, 81671, 81672], [81673, 81674, 81675, 81676, 81677, 81678, 81679, 81680, 81681, 81682, 81683, 81684, 81685, 81686, 81687, 81688, 81689, 81690, 81691, 81692, 81693, 81694, 81695, 81696, 81697, 81698, 81699, 81700, 81701, 81702, 81703, 81704, 81705, 81706, 81707, 81708, 81709, 81710, 81711, 81712, 81713, 81714, 81715, 81716, 81717, 81718, 81719, 81720, 81721, 81722, 81723, 81724, 81725, 81726, 81727, 81728, 81729, 81730, 81731, 81732, 81733, 81734, 81735, 81736], [81737, 81738, 81739, 81740, 81741, 81742, 81743, 81744, 81745, 81746, 81747, 81748, 81749, 81750, 81751, 81752, 81753, 81754, 81755, 81756, 81757, 81758, 81759, 81760, 81761, 81762, 81763, 81764, 81765, 81766, 81767, 81768, 81769, 81770, 81771, 81772, 81773, 81774, 81775, 81776, 81777, 81778, 81779, 81780, 81781, 81782, 81783, 81784, 81785, 81786, 81787, 81788, 81789, 81790, 81791, 81792, 81793, 81794, 81795, 81796, 81797, 81798, 81799, 81800], [81801, 81802, 81803, 81804, 81805, 81806, 81807, 81808, 81809, 81810, 81811, 81812, 81813, 81814, 81815, 81816, 81817, 81818, 81819, 81820, 81821, 81822, 81823, 81824, 81825, 81826, 81827, 81828, 81829, 81830, 81831, 81832, 81833, 81834, 81835, 81836, 81837, 81838, 81839, 81840, 81841, 81842, 81843, 81844, 81845, 81846, 81847, 81848, 81849, 81850, 81851, 81852, 81853, 81854, 81855, 81856, 81857, 81858, 81859, 81860, 81861, 81862, 81863, 81864], [81865, 81866, 81867, 81868, 81869, 81870, 81871, 81872, 81873, 81874, 81875, 81876, 81877, 81878, 81879, 81880, 81881, 81882, 81883, 81884, 81885, 81886, 81887, 81888, 81889, 81890, 81891, 81892, 81893, 81894, 81895, 81896, 81897, 81898, 81899, 81900, 81901, 81902, 81903, 81904, 81905, 81906, 81907, 81908, 81909, 81910, 81911, 81912, 81913, 81914, 81915, 81916, 81917, 81918, 81919, 81920, 81921, 81922, 81923, 81924, 81925, 81926, 81927, 81928]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=181,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([81929, 81930, 81931, 81932, 81933, 81934, 81935, 81936, 81937, 81938, 81939, 81940, 81941, 81942, 81943, 81944, 81945, 81946, 81947, 81948, 81949, 81950, 81951, 81952, 81953, 81954, 81955, 81956, 81957, 81958, 81959, 81960, 81961, 81962, 81963, 81964, 81965, 81966, 81967, 81968, 81969, 81970, 81971, 81972, 81973, 81974, 81975, 81976, 81977, 81978, 81979, 81980, 81981, 81982, 81983, 81984, 81985, 81986, 81987, 81988, 81989, 81990, 81991, 81992], [81993, 81994, 81995, 81996, 81997, 81998, 81999, 82000, 82001, 82002, 82003, 82004, 82005, 82006, 82007, 82008, 82009, 82010, 82011, 82012, 82013, 82014, 82015, 82016, 82017, 82018, 82019, 82020, 82021, 82022, 82023, 82024, 82025, 82026, 82027, 82028, 82029, 82030, 82031, 82032, 82033, 82034, 82035, 82036, 82037, 82038, 82039, 82040, 82041, 82042, 82043, 82044, 82045, 82046, 82047, 82048, 82049, 82050, 82051, 82052, 82053, 82054, 82055, 82056], [82057, 82058, 82059, 82060, 82061, 82062, 82063, 82064, 82065, 82066, 82067, 82068, 82069, 82070, 82071, 82072, 82073, 82074, 82075, 82076, 82077, 82078, 82079, 82080, 82081, 82082, 82083, 82084, 82085, 82086, 82087, 82088, 82089, 82090, 82091, 82092, 82093, 82094, 82095, 82096, 82097, 82098, 82099, 82100, 82101, 82102, 82103, 82104, 82105, 82106, 82107, 82108, 82109, 82110, 82111, 82112, 82113, 82114, 82115, 82116, 82117, 82118, 82119, 82120], [82121, 82122, 82123, 82124, 82125, 82126, 82127, 82128, 82129, 82130, 82131, 82132, 82133, 82134, 82135, 82136, 82137, 82138, 82139, 82140, 82141, 82142, 82143, 82144, 82145, 82146, 82147, 82148, 82149, 82150, 82151, 82152, 82153, 82154, 82155, 82156, 82157, 82158, 82159, 82160, 82161, 82162, 82163, 82164, 82165, 82166, 82167, 82168, 82169, 82170, 82171, 82172, 82173, 82174, 82175, 82176, 82177, 82178, 82179, 82180, 82181, 82182, 82183, 82184], [82185, 82186, 82187, 82188, 82189, 82190, 82191, 82192, 82193, 82194, 82195, 82196, 82197, 82198, 82199, 82200, 82201, 82202, 82203, 82204, 82205, 82206, 82207, 82208, 82209, 82210, 82211, 82212, 82213, 82214, 82215, 82216, 82217, 82218, 82219, 82220, 82221, 82222, 82223, 82224, 82225, 82226, 82227, 82228, 82229, 82230, 82231, 82232, 82233, 82234, 82235, 82236, 82237, 82238, 82239, 82240, 82241, 82242, 82243, 82244, 82245, 82246, 82247, 82248], [82249, 82250, 82251, 82252, 82253, 82254, 82255, 82256, 82257, 82258, 82259, 82260, 82261, 82262, 82263, 82264, 82265, 82266, 82267, 82268, 82269, 82270, 82271, 82272, 82273, 82274, 82275, 82276, 82277, 82278, 82279, 82280, 82281, 82282, 82283, 82284, 82285, 82286, 82287, 82288, 82289, 82290, 82291, 82292, 82293, 82294, 82295, 82296, 82297, 82298, 82299, 82300, 82301, 82302, 82303, 82304, 82305, 82306, 82307, 82308, 82309, 82310, 82311, 82312], [82313, 82314, 82315, 82316, 82317, 82318, 82319, 82320, 82321, 82322, 82323, 82324, 82325, 82326, 82327, 82328, 82329, 82330, 82331, 82332, 82333, 82334, 82335, 82336, 82337, 82338, 82339, 82340, 82341, 82342, 82343, 82344, 82345, 82346, 82347, 82348, 82349, 82350, 82351, 82352, 82353, 82354, 82355, 82356, 82357, 82358, 82359, 82360, 82361, 82362, 82363, 82364, 82365, 82366, 82367, 82368, 82369, 82370, 82371, 82372, 82373, 82374, 82375, 82376]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=182,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([82377, 82378, 82379, 82380, 82381, 82382, 82383, 82384, 82385, 82386, 82387, 82388, 82389, 82390, 82391, 82392, 82393, 82394, 82395, 82396, 82397, 82398, 82399, 82400, 82401, 82402, 82403, 82404, 82405, 82406, 82407, 82408, 82409, 82410, 82411, 82412, 82413, 82414, 82415, 82416, 82417, 82418, 82419, 82420, 82421, 82422, 82423, 82424, 82425, 82426, 82427, 82428, 82429, 82430, 82431, 82432, 82433, 82434, 82435, 82436, 82437, 82438, 82439, 82440], [82441, 82442, 82443, 82444, 82445, 82446, 82447, 82448, 82449, 82450, 82451, 82452, 82453, 82454, 82455, 82456, 82457, 82458, 82459, 82460, 82461, 82462, 82463, 82464, 82465, 82466, 82467, 82468, 82469, 82470, 82471, 82472, 82473, 82474, 82475, 82476, 82477, 82478, 82479, 82480, 82481, 82482, 82483, 82484, 82485, 82486, 82487, 82488, 82489, 82490, 82491, 82492, 82493, 82494, 82495, 82496, 82497, 82498, 82499, 82500, 82501, 82502, 82503, 82504], [82505, 82506, 82507, 82508, 82509, 82510, 82511, 82512, 82513, 82514, 82515, 82516, 82517, 82518, 82519, 82520, 82521, 82522, 82523, 82524, 82525, 82526, 82527, 82528, 82529, 82530, 82531, 82532, 82533, 82534, 82535, 82536, 82537, 82538, 82539, 82540, 82541, 82542, 82543, 82544, 82545, 82546, 82547, 82548, 82549, 82550, 82551, 82552, 82553, 82554, 82555, 82556, 82557, 82558, 82559, 82560, 82561, 82562, 82563, 82564, 82565, 82566, 82567, 82568], [82569, 82570, 82571, 82572, 82573, 82574, 82575, 82576, 82577, 82578, 82579, 82580, 82581, 82582, 82583, 82584, 82585, 82586, 82587, 82588, 82589, 82590, 82591, 82592, 82593, 82594, 82595, 82596, 82597, 82598, 82599, 82600, 82601, 82602, 82603, 82604, 82605, 82606, 82607, 82608, 82609, 82610, 82611, 82612, 82613, 82614, 82615, 82616, 82617, 82618, 82619, 82620, 82621, 82622, 82623, 82624, 82625, 82626, 82627, 82628, 82629, 82630, 82631, 82632], [82633, 82634, 82635, 82636, 82637, 82638, 82639, 82640, 82641, 82642, 82643, 82644, 82645, 82646, 82647, 82648, 82649, 82650, 82651, 82652, 82653, 82654, 82655, 82656, 82657, 82658, 82659, 82660, 82661, 82662, 82663, 82664, 82665, 82666, 82667, 82668, 82669, 82670, 82671, 82672, 82673, 82674, 82675, 82676, 82677, 82678, 82679, 82680, 82681, 82682, 82683, 82684, 82685, 82686, 82687, 82688, 82689, 82690, 82691, 82692, 82693, 82694, 82695, 82696], [82697, 82698, 82699, 82700, 82701, 82702, 82703, 82704, 82705, 82706, 82707, 82708, 82709, 82710, 82711, 82712, 82713, 82714, 82715, 82716, 82717, 82718, 82719, 82720, 82721, 82722, 82723, 82724, 82725, 82726, 82727, 82728, 82729, 82730, 82731, 82732, 82733, 82734, 82735, 82736, 82737, 82738, 82739, 82740, 82741, 82742, 82743, 82744, 82745, 82746, 82747, 82748, 82749, 82750, 82751, 82752, 82753, 82754, 82755, 82756, 82757, 82758, 82759, 82760], [82761, 82762, 82763, 82764, 82765, 82766, 82767, 82768, 82769, 82770, 82771, 82772, 82773, 82774, 82775, 82776, 82777, 82778, 82779, 82780, 82781, 82782, 82783, 82784, 82785, 82786, 82787, 82788, 82789, 82790, 82791, 82792, 82793, 82794, 82795, 82796, 82797, 82798, 82799, 82800, 82801, 82802, 82803, 82804, 82805, 82806, 82807, 82808, 82809, 82810, 82811, 82812, 82813, 82814, 82815, 82816, 82817, 82818, 82819, 82820, 82821, 82822, 82823, 82824]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=183,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([82825, 82826, 82827, 82828, 82829, 82830, 82831, 82832, 82833, 82834, 82835, 82836, 82837, 82838, 82839, 82840, 82841, 82842, 82843, 82844, 82845, 82846, 82847, 82848, 82849, 82850, 82851, 82852, 82853, 82854, 82855, 82856, 82857, 82858, 82859, 82860, 82861, 82862, 82863, 82864, 82865, 82866, 82867, 82868, 82869, 82870, 82871, 82872, 82873, 82874, 82875, 82876, 82877, 82878, 82879, 82880, 82881, 82882, 82883, 82884, 82885, 82886, 82887, 82888], [82889, 82890, 82891, 82892, 82893, 82894, 82895, 82896, 82897, 82898, 82899, 82900, 82901, 82902, 82903, 82904, 82905, 82906, 82907, 82908, 82909, 82910, 82911, 82912, 82913, 82914, 82915, 82916, 82917, 82918, 82919, 82920, 82921, 82922, 82923, 82924, 82925, 82926, 82927, 82928, 82929, 82930, 82931, 82932, 82933, 82934, 82935, 82936, 82937, 82938, 82939, 82940, 82941, 82942, 82943, 82944, 82945, 82946, 82947, 82948, 82949, 82950, 82951, 82952], [82953, 82954, 82955, 82956, 82957, 82958, 82959, 82960, 82961, 82962, 82963, 82964, 82965, 82966, 82967, 82968, 82969, 82970, 82971, 82972, 82973, 82974, 82975, 82976, 82977, 82978, 82979, 82980, 82981, 82982, 82983, 82984, 82985, 82986, 82987, 82988, 82989, 82990, 82991, 82992, 82993, 82994, 82995, 82996, 82997, 82998, 82999, 83000, 83001, 83002, 83003, 83004, 83005, 83006, 83007, 83008, 83009, 83010, 83011, 83012, 83013, 83014, 83015, 83016], [83017, 83018, 83019, 83020, 83021, 83022, 83023, 83024, 83025, 83026, 83027, 83028, 83029, 83030, 83031, 83032, 83033, 83034, 83035, 83036, 83037, 83038, 83039, 83040, 83041, 83042, 83043, 83044, 83045, 83046, 83047, 83048, 83049, 83050, 83051, 83052, 83053, 83054, 83055, 83056, 83057, 83058, 83059, 83060, 83061, 83062, 83063, 83064, 83065, 83066, 83067, 83068, 83069, 83070, 83071, 83072, 83073, 83074, 83075, 83076, 83077, 83078, 83079, 83080], [83081, 83082, 83083, 83084, 83085, 83086, 83087, 83088, 83089, 83090, 83091, 83092, 83093, 83094, 83095, 83096, 83097, 83098, 83099, 83100, 83101, 83102, 83103, 83104, 83105, 83106, 83107, 83108, 83109, 83110, 83111, 83112, 83113, 83114, 83115, 83116, 83117, 83118, 83119, 83120, 83121, 83122, 83123, 83124, 83125, 83126, 83127, 83128, 83129, 83130, 83131, 83132, 83133, 83134, 83135, 83136, 83137, 83138, 83139, 83140, 83141, 83142, 83143, 83144], [83145, 83146, 83147, 83148, 83149, 83150, 83151, 83152, 83153, 83154, 83155, 83156, 83157, 83158, 83159, 83160, 83161, 83162, 83163, 83164, 83165, 83166, 83167, 83168, 83169, 83170, 83171, 83172, 83173, 83174, 83175, 83176, 83177, 83178, 83179, 83180, 83181, 83182, 83183, 83184, 83185, 83186, 83187, 83188, 83189, 83190, 83191, 83192, 83193, 83194, 83195, 83196, 83197, 83198, 83199, 83200, 83201, 83202, 83203, 83204, 83205, 83206, 83207, 83208], [83209, 83210, 83211, 83212, 83213, 83214, 83215, 83216, 83217, 83218, 83219, 83220, 83221, 83222, 83223, 83224, 83225, 83226, 83227, 83228, 83229, 83230, 83231, 83232, 83233, 83234, 83235, 83236, 83237, 83238, 83239, 83240, 83241, 83242, 83243, 83244, 83245, 83246, 83247, 83248, 83249, 83250, 83251, 83252, 83253, 83254, 83255, 83256, 83257, 83258, 83259, 83260, 83261, 83262, 83263, 83264, 83265, 83266, 83267, 83268, 83269, 83270, 83271, 83272]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=184,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([83273, 83274, 83275, 83276, 83277, 83278, 83279, 83280, 83281, 83282, 83283, 83284, 83285, 83286, 83287, 83288, 83289, 83290, 83291, 83292, 83293, 83294, 83295, 83296, 83297, 83298, 83299, 83300, 83301, 83302, 83303, 83304, 83305, 83306, 83307, 83308, 83309, 83310, 83311, 83312, 83313, 83314, 83315, 83316, 83317, 83318, 83319, 83320, 83321, 83322, 83323, 83324, 83325, 83326, 83327, 83328, 83329, 83330, 83331, 83332, 83333, 83334, 83335, 83336], [83337, 83338, 83339, 83340, 83341, 83342, 83343, 83344, 83345, 83346, 83347, 83348, 83349, 83350, 83351, 83352, 83353, 83354, 83355, 83356, 83357, 83358, 83359, 83360, 83361, 83362, 83363, 83364, 83365, 83366, 83367, 83368, 83369, 83370, 83371, 83372, 83373, 83374, 83375, 83376, 83377, 83378, 83379, 83380, 83381, 83382, 83383, 83384, 83385, 83386, 83387, 83388, 83389, 83390, 83391, 83392, 83393, 83394, 83395, 83396, 83397, 83398, 83399, 83400], [83401, 83402, 83403, 83404, 83405, 83406, 83407, 83408, 83409, 83410, 83411, 83412, 83413, 83414, 83415, 83416, 83417, 83418, 83419, 83420, 83421, 83422, 83423, 83424, 83425, 83426, 83427, 83428, 83429, 83430, 83431, 83432, 83433, 83434, 83435, 83436, 83437, 83438, 83439, 83440, 83441, 83442, 83443, 83444, 83445, 83446, 83447, 83448, 83449, 83450, 83451, 83452, 83453, 83454, 83455, 83456, 83457, 83458, 83459, 83460, 83461, 83462, 83463, 83464], [83465, 83466, 83467, 83468, 83469, 83470, 83471, 83472, 83473, 83474, 83475, 83476, 83477, 83478, 83479, 83480, 83481, 83482, 83483, 83484, 83485, 83486, 83487, 83488, 83489, 83490, 83491, 83492, 83493, 83494, 83495, 83496, 83497, 83498, 83499, 83500, 83501, 83502, 83503, 83504, 83505, 83506, 83507, 83508, 83509, 83510, 83511, 83512, 83513, 83514, 83515, 83516, 83517, 83518, 83519, 83520, 83521, 83522, 83523, 83524, 83525, 83526, 83527, 83528], [83529, 83530, 83531, 83532, 83533, 83534, 83535, 83536, 83537, 83538, 83539, 83540, 83541, 83542, 83543, 83544, 83545, 83546, 83547, 83548, 83549, 83550, 83551, 83552, 83553, 83554, 83555, 83556, 83557, 83558, 83559, 83560, 83561, 83562, 83563, 83564, 83565, 83566, 83567, 83568, 83569, 83570, 83571, 83572, 83573, 83574, 83575, 83576, 83577, 83578, 83579, 83580, 83581, 83582, 83583, 83584, 83585, 83586, 83587, 83588, 83589, 83590, 83591, 83592], [83593, 83594, 83595, 83596, 83597, 83598, 83599, 83600, 83601, 83602, 83603, 83604, 83605, 83606, 83607, 83608, 83609, 83610, 83611, 83612, 83613, 83614, 83615, 83616, 83617, 83618, 83619, 83620, 83621, 83622, 83623, 83624, 83625, 83626, 83627, 83628, 83629, 83630, 83631, 83632, 83633, 83634, 83635, 83636, 83637, 83638, 83639, 83640, 83641, 83642, 83643, 83644, 83645, 83646, 83647, 83648, 83649, 83650, 83651, 83652, 83653, 83654, 83655, 83656], [83657, 83658, 83659, 83660, 83661, 83662, 83663, 83664, 83665, 83666, 83667, 83668, 83669, 83670, 83671, 83672, 83673, 83674, 83675, 83676, 83677, 83678, 83679, 83680, 83681, 83682, 83683, 83684, 83685, 83686, 83687, 83688, 83689, 83690, 83691, 83692, 83693, 83694, 83695, 83696, 83697, 83698, 83699, 83700, 83701, 83702, 83703, 83704, 83705, 83706, 83707, 83708, 83709, 83710, 83711, 83712, 83713, 83714, 83715, 83716, 83717, 83718, 83719, 83720]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=185,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([83721, 83722, 83723, 83724, 83725, 83726, 83727, 83728, 83729, 83730, 83731, 83732, 83733, 83734, 83735, 83736, 83737, 83738, 83739, 83740, 83741, 83742, 83743, 83744, 83745, 83746, 83747, 83748, 83749, 83750, 83751, 83752, 83753, 83754, 83755, 83756, 83757, 83758, 83759, 83760, 83761, 83762, 83763, 83764, 83765, 83766, 83767, 83768, 83769, 83770, 83771, 83772, 83773, 83774, 83775, 83776, 83777, 83778, 83779, 83780, 83781, 83782, 83783, 83784], [83785, 83786, 83787, 83788, 83789, 83790, 83791, 83792, 83793, 83794, 83795, 83796, 83797, 83798, 83799, 83800, 83801, 83802, 83803, 83804, 83805, 83806, 83807, 83808, 83809, 83810, 83811, 83812, 83813, 83814, 83815, 83816, 83817, 83818, 83819, 83820, 83821, 83822, 83823, 83824, 83825, 83826, 83827, 83828, 83829, 83830, 83831, 83832, 83833, 83834, 83835, 83836, 83837, 83838, 83839, 83840, 83841, 83842, 83843, 83844, 83845, 83846, 83847, 83848], [83849, 83850, 83851, 83852, 83853, 83854, 83855, 83856, 83857, 83858, 83859, 83860, 83861, 83862, 83863, 83864, 83865, 83866, 83867, 83868, 83869, 83870, 83871, 83872, 83873, 83874, 83875, 83876, 83877, 83878, 83879, 83880, 83881, 83882, 83883, 83884, 83885, 83886, 83887, 83888, 83889, 83890, 83891, 83892, 83893, 83894, 83895, 83896, 83897, 83898, 83899, 83900, 83901, 83902, 83903, 83904, 83905, 83906, 83907, 83908, 83909, 83910, 83911, 83912], [83913, 83914, 83915, 83916, 83917, 83918, 83919, 83920, 83921, 83922, 83923, 83924, 83925, 83926, 83927, 83928, 83929, 83930, 83931, 83932, 83933, 83934, 83935, 83936, 83937, 83938, 83939, 83940, 83941, 83942, 83943, 83944, 83945, 83946, 83947, 83948, 83949, 83950, 83951, 83952, 83953, 83954, 83955, 83956, 83957, 83958, 83959, 83960, 83961, 83962, 83963, 83964, 83965, 83966, 83967, 83968, 83969, 83970, 83971, 83972, 83973, 83974, 83975, 83976], [83977, 83978, 83979, 83980, 83981, 83982, 83983, 83984, 83985, 83986, 83987, 83988, 83989, 83990, 83991, 83992, 83993, 83994, 83995, 83996, 83997, 83998, 83999, 84000, 84001, 84002, 84003, 84004, 84005, 84006, 84007, 84008, 84009, 84010, 84011, 84012, 84013, 84014, 84015, 84016, 84017, 84018, 84019, 84020, 84021, 84022, 84023, 84024, 84025, 84026, 84027, 84028, 84029, 84030, 84031, 84032, 84033, 84034, 84035, 84036, 84037, 84038, 84039, 84040], [84041, 84042, 84043, 84044, 84045, 84046, 84047, 84048, 84049, 84050, 84051, 84052, 84053, 84054, 84055, 84056, 84057, 84058, 84059, 84060, 84061, 84062, 84063, 84064, 84065, 84066, 84067, 84068, 84069, 84070, 84071, 84072, 84073, 84074, 84075, 84076, 84077, 84078, 84079, 84080, 84081, 84082, 84083, 84084, 84085, 84086, 84087, 84088, 84089, 84090, 84091, 84092, 84093, 84094, 84095, 84096, 84097, 84098, 84099, 84100, 84101, 84102, 84103, 84104], [84105, 84106, 84107, 84108, 84109, 84110, 84111, 84112, 84113, 84114, 84115, 84116, 84117, 84118, 84119, 84120, 84121, 84122, 84123, 84124, 84125, 84126, 84127, 84128, 84129, 84130, 84131, 84132, 84133, 84134, 84135, 84136, 84137, 84138, 84139, 84140, 84141, 84142, 84143, 84144, 84145, 84146, 84147, 84148, 84149, 84150, 84151, 84152, 84153, 84154, 84155, 84156, 84157, 84158, 84159, 84160, 84161, 84162, 84163, 84164, 84165, 84166, 84167, 84168]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=186,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([84169, 84170, 84171, 84172, 84173, 84174, 84175, 84176, 84177, 84178, 84179, 84180, 84181, 84182, 84183, 84184, 84185, 84186, 84187, 84188, 84189, 84190, 84191, 84192, 84193, 84194, 84195, 84196, 84197, 84198, 84199, 84200, 84201, 84202, 84203, 84204, 84205, 84206, 84207, 84208, 84209, 84210, 84211, 84212, 84213, 84214, 84215, 84216, 84217, 84218, 84219, 84220, 84221, 84222, 84223, 84224, 84225, 84226, 84227, 84228, 84229, 84230, 84231, 84232], [84233, 84234, 84235, 84236, 84237, 84238, 84239, 84240, 84241, 84242, 84243, 84244, 84245, 84246, 84247, 84248, 84249, 84250, 84251, 84252, 84253, 84254, 84255, 84256, 84257, 84258, 84259, 84260, 84261, 84262, 84263, 84264, 84265, 84266, 84267, 84268, 84269, 84270, 84271, 84272, 84273, 84274, 84275, 84276, 84277, 84278, 84279, 84280, 84281, 84282, 84283, 84284, 84285, 84286, 84287, 84288, 84289, 84290, 84291, 84292, 84293, 84294, 84295, 84296], [84297, 84298, 84299, 84300, 84301, 84302, 84303, 84304, 84305, 84306, 84307, 84308, 84309, 84310, 84311, 84312, 84313, 84314, 84315, 84316, 84317, 84318, 84319, 84320, 84321, 84322, 84323, 84324, 84325, 84326, 84327, 84328, 84329, 84330, 84331, 84332, 84333, 84334, 84335, 84336, 84337, 84338, 84339, 84340, 84341, 84342, 84343, 84344, 84345, 84346, 84347, 84348, 84349, 84350, 84351, 84352, 84353, 84354, 84355, 84356, 84357, 84358, 84359, 84360], [84361, 84362, 84363, 84364, 84365, 84366, 84367, 84368, 84369, 84370, 84371, 84372, 84373, 84374, 84375, 84376, 84377, 84378, 84379, 84380, 84381, 84382, 84383, 84384, 84385, 84386, 84387, 84388, 84389, 84390, 84391, 84392, 84393, 84394, 84395, 84396, 84397, 84398, 84399, 84400, 84401, 84402, 84403, 84404, 84405, 84406, 84407, 84408, 84409, 84410, 84411, 84412, 84413, 84414, 84415, 84416, 84417, 84418, 84419, 84420, 84421, 84422, 84423, 84424], [84425, 84426, 84427, 84428, 84429, 84430, 84431, 84432, 84433, 84434, 84435, 84436, 84437, 84438, 84439, 84440, 84441, 84442, 84443, 84444, 84445, 84446, 84447, 84448, 84449, 84450, 84451, 84452, 84453, 84454, 84455, 84456, 84457, 84458, 84459, 84460, 84461, 84462, 84463, 84464, 84465, 84466, 84467, 84468, 84469, 84470, 84471, 84472, 84473, 84474, 84475, 84476, 84477, 84478, 84479, 84480, 84481, 84482, 84483, 84484, 84485, 84486, 84487, 84488], [84489, 84490, 84491, 84492, 84493, 84494, 84495, 84496, 84497, 84498, 84499, 84500, 84501, 84502, 84503, 84504, 84505, 84506, 84507, 84508, 84509, 84510, 84511, 84512, 84513, 84514, 84515, 84516, 84517, 84518, 84519, 84520, 84521, 84522, 84523, 84524, 84525, 84526, 84527, 84528, 84529, 84530, 84531, 84532, 84533, 84534, 84535, 84536, 84537, 84538, 84539, 84540, 84541, 84542, 84543, 84544, 84545, 84546, 84547, 84548, 84549, 84550, 84551, 84552], [84553, 84554, 84555, 84556, 84557, 84558, 84559, 84560, 84561, 84562, 84563, 84564, 84565, 84566, 84567, 84568, 84569, 84570, 84571, 84572, 84573, 84574, 84575, 84576, 84577, 84578, 84579, 84580, 84581, 84582, 84583, 84584, 84585, 84586, 84587, 84588, 84589, 84590, 84591, 84592, 84593, 84594, 84595, 84596, 84597, 84598, 84599, 84600, 84601, 84602, 84603, 84604, 84605, 84606, 84607, 84608, 84609, 84610, 84611, 84612, 84613, 84614, 84615, 84616]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=187,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([84617, 84618, 84619, 84620, 84621, 84622, 84623, 84624, 84625, 84626, 84627, 84628, 84629, 84630, 84631, 84632, 84633, 84634, 84635, 84636, 84637, 84638, 84639, 84640, 84641, 84642, 84643, 84644, 84645, 84646, 84647, 84648, 84649, 84650, 84651, 84652, 84653, 84654, 84655, 84656, 84657, 84658, 84659, 84660, 84661, 84662, 84663, 84664, 84665, 84666, 84667, 84668, 84669, 84670, 84671, 84672, 84673, 84674, 84675, 84676, 84677, 84678, 84679, 84680], [84681, 84682, 84683, 84684, 84685, 84686, 84687, 84688, 84689, 84690, 84691, 84692, 84693, 84694, 84695, 84696, 84697, 84698, 84699, 84700, 84701, 84702, 84703, 84704, 84705, 84706, 84707, 84708, 84709, 84710, 84711, 84712, 84713, 84714, 84715, 84716, 84717, 84718, 84719, 84720, 84721, 84722, 84723, 84724, 84725, 84726, 84727, 84728, 84729, 84730, 84731, 84732, 84733, 84734, 84735, 84736, 84737, 84738, 84739, 84740, 84741, 84742, 84743, 84744], [84745, 84746, 84747, 84748, 84749, 84750, 84751, 84752, 84753, 84754, 84755, 84756, 84757, 84758, 84759, 84760, 84761, 84762, 84763, 84764, 84765, 84766, 84767, 84768, 84769, 84770, 84771, 84772, 84773, 84774, 84775, 84776, 84777, 84778, 84779, 84780, 84781, 84782, 84783, 84784, 84785, 84786, 84787, 84788, 84789, 84790, 84791, 84792, 84793, 84794, 84795, 84796, 84797, 84798, 84799, 84800, 84801, 84802, 84803, 84804, 84805, 84806, 84807, 84808], [84809, 84810, 84811, 84812, 84813, 84814, 84815, 84816, 84817, 84818, 84819, 84820, 84821, 84822, 84823, 84824, 84825, 84826, 84827, 84828, 84829, 84830, 84831, 84832, 84833, 84834, 84835, 84836, 84837, 84838, 84839, 84840, 84841, 84842, 84843, 84844, 84845, 84846, 84847, 84848, 84849, 84850, 84851, 84852, 84853, 84854, 84855, 84856, 84857, 84858, 84859, 84860, 84861, 84862, 84863, 84864, 84865, 84866, 84867, 84868, 84869, 84870, 84871, 84872], [84873, 84874, 84875, 84876, 84877, 84878, 84879, 84880, 84881, 84882, 84883, 84884, 84885, 84886, 84887, 84888, 84889, 84890, 84891, 84892, 84893, 84894, 84895, 84896, 84897, 84898, 84899, 84900, 84901, 84902, 84903, 84904, 84905, 84906, 84907, 84908, 84909, 84910, 84911, 84912, 84913, 84914, 84915, 84916, 84917, 84918, 84919, 84920, 84921, 84922, 84923, 84924, 84925, 84926, 84927, 84928, 84929, 84930, 84931, 84932, 84933, 84934, 84935, 84936], [84937, 84938, 84939, 84940, 84941, 84942, 84943, 84944, 84945, 84946, 84947, 84948, 84949, 84950, 84951, 84952, 84953, 84954, 84955, 84956, 84957, 84958, 84959, 84960, 84961, 84962, 84963, 84964, 84965, 84966, 84967, 84968, 84969, 84970, 84971, 84972, 84973, 84974, 84975, 84976, 84977, 84978, 84979, 84980, 84981, 84982, 84983, 84984, 84985, 84986, 84987, 84988, 84989, 84990, 84991, 84992, 84993, 84994, 84995, 84996, 84997, 84998, 84999, 85000], [85001, 85002, 85003, 85004, 85005, 85006, 85007, 85008, 85009, 85010, 85011, 85012, 85013, 85014, 85015, 85016, 85017, 85018, 85019, 85020, 85021, 85022, 85023, 85024, 85025, 85026, 85027, 85028, 85029, 85030, 85031, 85032, 85033, 85034, 85035, 85036, 85037, 85038, 85039, 85040, 85041, 85042, 85043, 85044, 85045, 85046, 85047, 85048, 85049, 85050, 85051, 85052, 85053, 85054, 85055, 85056, 85057, 85058, 85059, 85060, 85061, 85062, 85063, 85064]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=188,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([85065, 85066, 85067, 85068, 85069, 85070, 85071, 85072, 85073, 85074, 85075, 85076, 85077, 85078, 85079, 85080, 85081, 85082, 85083, 85084, 85085, 85086, 85087, 85088, 85089, 85090, 85091, 85092, 85093, 85094, 85095, 85096, 85097, 85098, 85099, 85100, 85101, 85102, 85103, 85104, 85105, 85106, 85107, 85108, 85109, 85110, 85111, 85112, 85113, 85114, 85115, 85116, 85117, 85118, 85119, 85120, 85121, 85122, 85123, 85124, 85125, 85126, 85127, 85128], [85129, 85130, 85131, 85132, 85133, 85134, 85135, 85136, 85137, 85138, 85139, 85140, 85141, 85142, 85143, 85144, 85145, 85146, 85147, 85148, 85149, 85150, 85151, 85152, 85153, 85154, 85155, 85156, 85157, 85158, 85159, 85160, 85161, 85162, 85163, 85164, 85165, 85166, 85167, 85168, 85169, 85170, 85171, 85172, 85173, 85174, 85175, 85176, 85177, 85178, 85179, 85180, 85181, 85182, 85183, 85184, 85185, 85186, 85187, 85188, 85189, 85190, 85191, 85192], [85193, 85194, 85195, 85196, 85197, 85198, 85199, 85200, 85201, 85202, 85203, 85204, 85205, 85206, 85207, 85208, 85209, 85210, 85211, 85212, 85213, 85214, 85215, 85216, 85217, 85218, 85219, 85220, 85221, 85222, 85223, 85224, 85225, 85226, 85227, 85228, 85229, 85230, 85231, 85232, 85233, 85234, 85235, 85236, 85237, 85238, 85239, 85240, 85241, 85242, 85243, 85244, 85245, 85246, 85247, 85248, 85249, 85250, 85251, 85252, 85253, 85254, 85255, 85256], [85257, 85258, 85259, 85260, 85261, 85262, 85263, 85264, 85265, 85266, 85267, 85268, 85269, 85270, 85271, 85272, 85273, 85274, 85275, 85276, 85277, 85278, 85279, 85280, 85281, 85282, 85283, 85284, 85285, 85286, 85287, 85288, 85289, 85290, 85291, 85292, 85293, 85294, 85295, 85296, 85297, 85298, 85299, 85300, 85301, 85302, 85303, 85304, 85305, 85306, 85307, 85308, 85309, 85310, 85311, 85312, 85313, 85314, 85315, 85316, 85317, 85318, 85319, 85320], [85321, 85322, 85323, 85324, 85325, 85326, 85327, 85328, 85329, 85330, 85331, 85332, 85333, 85334, 85335, 85336, 85337, 85338, 85339, 85340, 85341, 85342, 85343, 85344, 85345, 85346, 85347, 85348, 85349, 85350, 85351, 85352, 85353, 85354, 85355, 85356, 85357, 85358, 85359, 85360, 85361, 85362, 85363, 85364, 85365, 85366, 85367, 85368, 85369, 85370, 85371, 85372, 85373, 85374, 85375, 85376, 85377, 85378, 85379, 85380, 85381, 85382, 85383, 85384], [85385, 85386, 85387, 85388, 85389, 85390, 85391, 85392, 85393, 85394, 85395, 85396, 85397, 85398, 85399, 85400, 85401, 85402, 85403, 85404, 85405, 85406, 85407, 85408, 85409, 85410, 85411, 85412, 85413, 85414, 85415, 85416, 85417, 85418, 85419, 85420, 85421, 85422, 85423, 85424, 85425, 85426, 85427, 85428, 85429, 85430, 85431, 85432, 85433, 85434, 85435, 85436, 85437, 85438, 85439, 85440, 85441, 85442, 85443, 85444, 85445, 85446, 85447, 85448], [85449, 85450, 85451, 85452, 85453, 85454, 85455, 85456, 85457, 85458, 85459, 85460, 85461, 85462, 85463, 85464, 85465, 85466, 85467, 85468, 85469, 85470, 85471, 85472, 85473, 85474, 85475, 85476, 85477, 85478, 85479, 85480, 85481, 85482, 85483, 85484, 85485, 85486, 85487, 85488, 85489, 85490, 85491, 85492, 85493, 85494, 85495, 85496, 85497, 85498, 85499, 85500, 85501, 85502, 85503, 85504, 85505, 85506, 85507, 85508, 85509, 85510, 85511, 85512]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=189,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([85513, 85514, 85515, 85516, 85517, 85518, 85519, 85520, 85521, 85522, 85523, 85524, 85525, 85526, 85527, 85528, 85529, 85530, 85531, 85532, 85533, 85534, 85535, 85536, 85537, 85538, 85539, 85540, 85541, 85542, 85543, 85544, 85545, 85546, 85547, 85548, 85549, 85550, 85551, 85552, 85553, 85554, 85555, 85556, 85557, 85558, 85559, 85560, 85561, 85562, 85563, 85564, 85565, 85566, 85567, 85568, 85569, 85570, 85571, 85572, 85573, 85574, 85575, 85576], [85577, 85578, 85579, 85580, 85581, 85582, 85583, 85584, 85585, 85586, 85587, 85588, 85589, 85590, 85591, 85592, 85593, 85594, 85595, 85596, 85597, 85598, 85599, 85600, 85601, 85602, 85603, 85604, 85605, 85606, 85607, 85608, 85609, 85610, 85611, 85612, 85613, 85614, 85615, 85616, 85617, 85618, 85619, 85620, 85621, 85622, 85623, 85624, 85625, 85626, 85627, 85628, 85629, 85630, 85631, 85632, 85633, 85634, 85635, 85636, 85637, 85638, 85639, 85640], [85641, 85642, 85643, 85644, 85645, 85646, 85647, 85648, 85649, 85650, 85651, 85652, 85653, 85654, 85655, 85656, 85657, 85658, 85659, 85660, 85661, 85662, 85663, 85664, 85665, 85666, 85667, 85668, 85669, 85670, 85671, 85672, 85673, 85674, 85675, 85676, 85677, 85678, 85679, 85680, 85681, 85682, 85683, 85684, 85685, 85686, 85687, 85688, 85689, 85690, 85691, 85692, 85693, 85694, 85695, 85696, 85697, 85698, 85699, 85700, 85701, 85702, 85703, 85704], [85705, 85706, 85707, 85708, 85709, 85710, 85711, 85712, 85713, 85714, 85715, 85716, 85717, 85718, 85719, 85720, 85721, 85722, 85723, 85724, 85725, 85726, 85727, 85728, 85729, 85730, 85731, 85732, 85733, 85734, 85735, 85736, 85737, 85738, 85739, 85740, 85741, 85742, 85743, 85744, 85745, 85746, 85747, 85748, 85749, 85750, 85751, 85752, 85753, 85754, 85755, 85756, 85757, 85758, 85759, 85760, 85761, 85762, 85763, 85764, 85765, 85766, 85767, 85768], [85769, 85770, 85771, 85772, 85773, 85774, 85775, 85776, 85777, 85778, 85779, 85780, 85781, 85782, 85783, 85784, 85785, 85786, 85787, 85788, 85789, 85790, 85791, 85792, 85793, 85794, 85795, 85796, 85797, 85798, 85799, 85800, 85801, 85802, 85803, 85804, 85805, 85806, 85807, 85808, 85809, 85810, 85811, 85812, 85813, 85814, 85815, 85816, 85817, 85818, 85819, 85820, 85821, 85822, 85823, 85824, 85825, 85826, 85827, 85828, 85829, 85830, 85831, 85832], [85833, 85834, 85835, 85836, 85837, 85838, 85839, 85840, 85841, 85842, 85843, 85844, 85845, 85846, 85847, 85848, 85849, 85850, 85851, 85852, 85853, 85854, 85855, 85856, 85857, 85858, 85859, 85860, 85861, 85862, 85863, 85864, 85865, 85866, 85867, 85868, 85869, 85870, 85871, 85872, 85873, 85874, 85875, 85876, 85877, 85878, 85879, 85880, 85881, 85882, 85883, 85884, 85885, 85886, 85887, 85888, 85889, 85890, 85891, 85892, 85893, 85894, 85895, 85896], [85897, 85898, 85899, 85900, 85901, 85902, 85903, 85904, 85905, 85906, 85907, 85908, 85909, 85910, 85911, 85912, 85913, 85914, 85915, 85916, 85917, 85918, 85919, 85920, 85921, 85922, 85923, 85924, 85925, 85926, 85927, 85928, 85929, 85930, 85931, 85932, 85933, 85934, 85935, 85936, 85937, 85938, 85939, 85940, 85941, 85942, 85943, 85944, 85945, 85946, 85947, 85948, 85949, 85950, 85951, 85952, 85953, 85954, 85955, 85956, 85957, 85958, 85959, 85960]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=190,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([85961, 85962, 85963, 85964, 85965, 85966, 85967, 85968, 85969, 85970, 85971, 85972, 85973, 85974, 85975, 85976, 85977, 85978, 85979, 85980, 85981, 85982, 85983, 85984, 85985, 85986, 85987, 85988, 85989, 85990, 85991, 85992, 85993, 85994, 85995, 85996, 85997, 85998, 85999, 86000, 86001, 86002, 86003, 86004, 86005, 86006, 86007, 86008, 86009, 86010, 86011, 86012, 86013, 86014, 86015, 86016, 86017, 86018, 86019, 86020, 86021, 86022, 86023, 86024], [86025, 86026, 86027, 86028, 86029, 86030, 86031, 86032, 86033, 86034, 86035, 86036, 86037, 86038, 86039, 86040, 86041, 86042, 86043, 86044, 86045, 86046, 86047, 86048, 86049, 86050, 86051, 86052, 86053, 86054, 86055, 86056, 86057, 86058, 86059, 86060, 86061, 86062, 86063, 86064, 86065, 86066, 86067, 86068, 86069, 86070, 86071, 86072, 86073, 86074, 86075, 86076, 86077, 86078, 86079, 86080, 86081, 86082, 86083, 86084, 86085, 86086, 86087, 86088], [86089, 86090, 86091, 86092, 86093, 86094, 86095, 86096, 86097, 86098, 86099, 86100, 86101, 86102, 86103, 86104, 86105, 86106, 86107, 86108, 86109, 86110, 86111, 86112, 86113, 86114, 86115, 86116, 86117, 86118, 86119, 86120, 86121, 86122, 86123, 86124, 86125, 86126, 86127, 86128, 86129, 86130, 86131, 86132, 86133, 86134, 86135, 86136, 86137, 86138, 86139, 86140, 86141, 86142, 86143, 86144, 86145, 86146, 86147, 86148, 86149, 86150, 86151, 86152], [86153, 86154, 86155, 86156, 86157, 86158, 86159, 86160, 86161, 86162, 86163, 86164, 86165, 86166, 86167, 86168, 86169, 86170, 86171, 86172, 86173, 86174, 86175, 86176, 86177, 86178, 86179, 86180, 86181, 86182, 86183, 86184, 86185, 86186, 86187, 86188, 86189, 86190, 86191, 86192, 86193, 86194, 86195, 86196, 86197, 86198, 86199, 86200, 86201, 86202, 86203, 86204, 86205, 86206, 86207, 86208, 86209, 86210, 86211, 86212, 86213, 86214, 86215, 86216], [86217, 86218, 86219, 86220, 86221, 86222, 86223, 86224, 86225, 86226, 86227, 86228, 86229, 86230, 86231, 86232, 86233, 86234, 86235, 86236, 86237, 86238, 86239, 86240, 86241, 86242, 86243, 86244, 86245, 86246, 86247, 86248, 86249, 86250, 86251, 86252, 86253, 86254, 86255, 86256, 86257, 86258, 86259, 86260, 86261, 86262, 86263, 86264, 86265, 86266, 86267, 86268, 86269, 86270, 86271, 86272, 86273, 86274, 86275, 86276, 86277, 86278, 86279, 86280], [86281, 86282, 86283, 86284, 86285, 86286, 86287, 86288, 86289, 86290, 86291, 86292, 86293, 86294, 86295, 86296, 86297, 86298, 86299, 86300, 86301, 86302, 86303, 86304, 86305, 86306, 86307, 86308, 86309, 86310, 86311, 86312, 86313, 86314, 86315, 86316, 86317, 86318, 86319, 86320, 86321, 86322, 86323, 86324, 86325, 86326, 86327, 86328, 86329, 86330, 86331, 86332, 86333, 86334, 86335, 86336, 86337, 86338, 86339, 86340, 86341, 86342, 86343, 86344], [86345, 86346, 86347, 86348, 86349, 86350, 86351, 86352, 86353, 86354, 86355, 86356, 86357, 86358, 86359, 86360, 86361, 86362, 86363, 86364, 86365, 86366, 86367, 86368, 86369, 86370, 86371, 86372, 86373, 86374, 86375, 86376, 86377, 86378, 86379, 86380, 86381, 86382, 86383, 86384, 86385, 86386, 86387, 86388, 86389, 86390, 86391, 86392, 86393, 86394, 86395, 86396, 86397, 86398, 86399, 86400, 86401, 86402, 86403, 86404, 86405, 86406, 86407, 86408]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=191,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([86409, 86410, 86411, 86412, 86413, 86414, 86415, 86416, 86417, 86418, 86419, 86420, 86421, 86422, 86423, 86424, 86425, 86426, 86427, 86428, 86429, 86430, 86431, 86432, 86433, 86434, 86435, 86436, 86437, 86438, 86439, 86440, 86441, 86442, 86443, 86444, 86445, 86446, 86447, 86448, 86449, 86450, 86451, 86452, 86453, 86454, 86455, 86456, 86457, 86458, 86459, 86460, 86461, 86462, 86463, 86464, 86465, 86466, 86467, 86468, 86469, 86470, 86471, 86472], [86473, 86474, 86475, 86476, 86477, 86478, 86479, 86480, 86481, 86482, 86483, 86484, 86485, 86486, 86487, 86488, 86489, 86490, 86491, 86492, 86493, 86494, 86495, 86496, 86497, 86498, 86499, 86500, 86501, 86502, 86503, 86504, 86505, 86506, 86507, 86508, 86509, 86510, 86511, 86512, 86513, 86514, 86515, 86516, 86517, 86518, 86519, 86520, 86521, 86522, 86523, 86524, 86525, 86526, 86527, 86528, 86529, 86530, 86531, 86532, 86533, 86534, 86535, 86536], [86537, 86538, 86539, 86540, 86541, 86542, 86543, 86544, 86545, 86546, 86547, 86548, 86549, 86550, 86551, 86552, 86553, 86554, 86555, 86556, 86557, 86558, 86559, 86560, 86561, 86562, 86563, 86564, 86565, 86566, 86567, 86568, 86569, 86570, 86571, 86572, 86573, 86574, 86575, 86576, 86577, 86578, 86579, 86580, 86581, 86582, 86583, 86584, 86585, 86586, 86587, 86588, 86589, 86590, 86591, 86592, 86593, 86594, 86595, 86596, 86597, 86598, 86599, 86600], [86601, 86602, 86603, 86604, 86605, 86606, 86607, 86608, 86609, 86610, 86611, 86612, 86613, 86614, 86615, 86616, 86617, 86618, 86619, 86620, 86621, 86622, 86623, 86624, 86625, 86626, 86627, 86628, 86629, 86630, 86631, 86632, 86633, 86634, 86635, 86636, 86637, 86638, 86639, 86640, 86641, 86642, 86643, 86644, 86645, 86646, 86647, 86648, 86649, 86650, 86651, 86652, 86653, 86654, 86655, 86656, 86657, 86658, 86659, 86660, 86661, 86662, 86663, 86664], [86665, 86666, 86667, 86668, 86669, 86670, 86671, 86672, 86673, 86674, 86675, 86676, 86677, 86678, 86679, 86680, 86681, 86682, 86683, 86684, 86685, 86686, 86687, 86688, 86689, 86690, 86691, 86692, 86693, 86694, 86695, 86696, 86697, 86698, 86699, 86700, 86701, 86702, 86703, 86704, 86705, 86706, 86707, 86708, 86709, 86710, 86711, 86712, 86713, 86714, 86715, 86716, 86717, 86718, 86719, 86720, 86721, 86722, 86723, 86724, 86725, 86726, 86727, 86728], [86729, 86730, 86731, 86732, 86733, 86734, 86735, 86736, 86737, 86738, 86739, 86740, 86741, 86742, 86743, 86744, 86745, 86746, 86747, 86748, 86749, 86750, 86751, 86752, 86753, 86754, 86755, 86756, 86757, 86758, 86759, 86760, 86761, 86762, 86763, 86764, 86765, 86766, 86767, 86768, 86769, 86770, 86771, 86772, 86773, 86774, 86775, 86776, 86777, 86778, 86779, 86780, 86781, 86782, 86783, 86784, 86785, 86786, 86787, 86788, 86789, 86790, 86791, 86792], [86793, 86794, 86795, 86796, 86797, 86798, 86799, 86800, 86801, 86802, 86803, 86804, 86805, 86806, 86807, 86808, 86809, 86810, 86811, 86812, 86813, 86814, 86815, 86816, 86817, 86818, 86819, 86820, 86821, 86822, 86823, 86824, 86825, 86826, 86827, 86828, 86829, 86830, 86831, 86832, 86833, 86834, 86835, 86836, 86837, 86838, 86839, 86840, 86841, 86842, 86843, 86844, 86845, 86846, 86847, 86848, 86849, 86850, 86851, 86852, 86853, 86854, 86855, 86856]),num_computed_tokens=0,lora_request=None), NewRequestData(req_id=192,prompt_token_ids_len=1024,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=True, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([86857, 86858, 86859, 86860, 86861, 86862, 86863, 86864, 86865, 86866, 86867, 86868, 86869, 86870, 86871, 86872, 86873, 86874, 86875, 86876, 86877, 86878, 86879, 86880, 86881, 86882, 86883, 86884, 86885, 86886, 86887, 86888, 86889, 86890, 86891, 86892, 86893, 86894, 86895, 86896, 86897, 86898, 86899, 86900, 86901, 86902, 86903, 86904, 86905, 86906, 86907, 86908], [86909, 86910, 86911, 86912, 86913, 86914, 86915, 86916, 86917, 86918, 86919, 86920, 86921, 86922, 86923, 86924, 86925, 86926, 86927, 86928, 86929, 86930, 86931, 86932, 86933, 86934, 86935, 86936, 86937, 86938, 86939, 86940, 86941, 86942, 86943, 86944, 86945, 86946, 86947, 86948, 86949, 86950, 86951, 86952, 86953, 86954, 86955, 86956, 86957, 86958, 86959, 86960], [86961, 86962, 86963, 86964, 86965, 86966, 86967, 86968, 86969, 86970, 86971, 86972, 86973, 86974, 86975, 86976, 86977, 86978, 86979, 86980, 86981, 86982, 86983, 86984, 86985, 86986, 86987, 86988, 86989, 86990, 86991, 86992, 86993, 86994, 86995, 86996, 86997, 86998, 86999, 87000, 87001, 87002, 87003, 87004, 87005, 87006, 87007, 87008, 87009, 87010, 87011, 87012], [87013, 87014, 87015, 87016, 87017, 87018, 87019, 87020, 87021, 87022, 87023, 87024, 87025, 87026, 87027, 87028, 87029, 87030, 87031, 87032, 87033, 87034, 87035, 87036, 87037, 87038, 87039, 87040, 87041, 87042, 87043, 87044, 87045, 87046, 87047, 87048, 87049, 87050, 87051, 87052, 87053, 87054, 87055, 87056, 87057, 87058, 87059, 87060, 87061, 87062, 87063, 87064], [87065, 87066, 87067, 87068, 87069, 87070, 87071, 87072, 87073, 87074, 87075, 87076, 87077, 87078, 87079, 87080, 87081, 87082, 87083, 87084, 87085, 87086, 87087, 87088, 87089, 87090, 87091, 87092, 87093, 87094, 87095, 87096, 87097, 87098, 87099, 87100, 87101, 87102, 87103, 87104, 87105, 87106, 87107, 87108, 87109, 87110, 87111, 87112, 87113, 87114, 87115, 87116], [87117, 87118, 87119, 87120, 87121, 87122, 87123, 87124, 87125, 87126, 87127, 87128, 87129, 87130, 87131, 87132, 87133, 87134, 87135, 87136, 87137, 87138, 87139, 87140, 87141, 87142, 87143, 87144, 87145, 87146, 87147, 87148, 87149, 87150, 87151, 87152, 87153, 87154, 87155, 87156, 87157, 87158, 87159, 87160, 87161, 87162, 87163, 87164, 87165, 87166, 87167, 87168], [87169, 87170, 87171, 87172, 87173, 87174, 87175, 87176, 87177, 87178, 87179, 87180, 87181, 87182, 87183, 87184, 87185, 87186, 87187, 87188, 87189, 87190, 87191, 87192, 87193, 87194, 87195, 87196, 87197, 87198, 87199, 87200, 87201, 87202, 87203, 87204, 87205, 87206, 87207, 87208, 87209, 87210, 87211, 87212, 87213, 87214, 87215, 87216, 87217, 87218, 87219, 87220]),num_computed_tokens=0,lora_request=None)], scheduled_cached_reqs=[CachedRequestData(req_id='0', resumed_from_preemption=false, new_token_ids=[236927], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1035), CachedRequestData(req_id='1', resumed_from_preemption=false, new_token_ids=[242079], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='2', resumed_from_preemption=false, new_token_ids=[672], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='3', resumed_from_preemption=false, new_token_ids=[236804], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='4', resumed_from_preemption=false, new_token_ids=[114951], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='5', resumed_from_preemption=false, new_token_ids=[21784], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='6', resumed_from_preemption=false, new_token_ids=[2627], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='7', resumed_from_preemption=false, new_token_ids=[236803], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='8', resumed_from_preemption=false, new_token_ids=[138], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='9', resumed_from_preemption=false, new_token_ids=[138], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='10', resumed_from_preemption=false, new_token_ids=[1860], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='11', resumed_from_preemption=false, new_token_ids=[237599], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='12', resumed_from_preemption=false, new_token_ids=[249512], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='13', resumed_from_preemption=false, new_token_ids=[106], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='14', resumed_from_preemption=false, new_token_ids=[506], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='15', resumed_from_preemption=false, new_token_ids=[26198], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1034), CachedRequestData(req_id='16', resumed_from_preemption=false, new_token_ids=[3274], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='17', resumed_from_preemption=false, new_token_ids=[236831], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='18', resumed_from_preemption=false, new_token_ids=[587], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='19', resumed_from_preemption=false, new_token_ids=[236886], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='20', resumed_from_preemption=false, new_token_ids=[2187], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='21', resumed_from_preemption=false, new_token_ids=[59978], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='22', resumed_from_preemption=false, new_token_ids=[67830], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='23', resumed_from_preemption=false, new_token_ids=[3509], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='24', resumed_from_preemption=false, new_token_ids=[1604], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='25', resumed_from_preemption=false, new_token_ids=[236748], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='26', resumed_from_preemption=false, new_token_ids=[1010], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='27', resumed_from_preemption=false, new_token_ids=[1184], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='28', resumed_from_preemption=false, new_token_ids=[236751], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='29', resumed_from_preemption=false, new_token_ids=[6481], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='30', resumed_from_preemption=false, new_token_ids=[583], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='31', resumed_from_preemption=false, new_token_ids=[110594], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1033), CachedRequestData(req_id='32', resumed_from_preemption=false, new_token_ids=[106], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='33', resumed_from_preemption=false, new_token_ids=[623], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='34', resumed_from_preemption=false, new_token_ids=[236827], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='35', resumed_from_preemption=false, new_token_ids=[236848], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='36', resumed_from_preemption=false, new_token_ids=[16440], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='37', resumed_from_preemption=false, new_token_ids=[387], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='38', resumed_from_preemption=false, new_token_ids=[3943], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='39', resumed_from_preemption=false, new_token_ids=[10830], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='40', resumed_from_preemption=false, new_token_ids=[236835], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='41', resumed_from_preemption=false, new_token_ids=[23929], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='42', resumed_from_preemption=false, new_token_ids=[5724], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='43', resumed_from_preemption=false, new_token_ids=[236770], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='44', resumed_from_preemption=false, new_token_ids=[104052], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='45', resumed_from_preemption=false, new_token_ids=[149982], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='46', resumed_from_preemption=false, new_token_ids=[463], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='47', resumed_from_preemption=false, new_token_ids=[236840], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1032), CachedRequestData(req_id='48', resumed_from_preemption=false, new_token_ids=[139050], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='49', resumed_from_preemption=false, new_token_ids=[17363], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='50', resumed_from_preemption=false, new_token_ids=[236746], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='51', resumed_from_preemption=false, new_token_ids=[22206], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='52', resumed_from_preemption=false, new_token_ids=[161395], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='53', resumed_from_preemption=false, new_token_ids=[244036], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='54', resumed_from_preemption=false, new_token_ids=[237188], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='55', resumed_from_preemption=false, new_token_ids=[2717], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='56', resumed_from_preemption=false, new_token_ids=[26320], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='57', resumed_from_preemption=false, new_token_ids=[236782], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='58', resumed_from_preemption=false, new_token_ids=[20669], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='59', resumed_from_preemption=false, new_token_ids=[464], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='60', resumed_from_preemption=false, new_token_ids=[11884], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='61', resumed_from_preemption=false, new_token_ids=[245903], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='62', resumed_from_preemption=false, new_token_ids=[3551], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='63', resumed_from_preemption=false, new_token_ids=[33842], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1031), CachedRequestData(req_id='64', resumed_from_preemption=false, new_token_ids=[29745], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='65', resumed_from_preemption=false, new_token_ids=[63150], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='66', resumed_from_preemption=false, new_token_ids=[236764], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='67', resumed_from_preemption=false, new_token_ids=[720], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='68', resumed_from_preemption=false, new_token_ids=[236743], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='69', resumed_from_preemption=false, new_token_ids=[236751], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='70', resumed_from_preemption=false, new_token_ids=[64727], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='71', resumed_from_preemption=false, new_token_ids=[4044], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='72', resumed_from_preemption=false, new_token_ids=[107], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='73', resumed_from_preemption=false, new_token_ids=[507], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='74', resumed_from_preemption=false, new_token_ids=[1849], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='75', resumed_from_preemption=false, new_token_ids=[236835], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='76', resumed_from_preemption=false, new_token_ids=[236825], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='77', resumed_from_preemption=false, new_token_ids=[2010], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='78', resumed_from_preemption=false, new_token_ids=[106], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='79', resumed_from_preemption=false, new_token_ids=[1312], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1030), CachedRequestData(req_id='80', resumed_from_preemption=false, new_token_ids=[107], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='81', resumed_from_preemption=false, new_token_ids=[138], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='82', resumed_from_preemption=false, new_token_ids=[107], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='83', resumed_from_preemption=false, new_token_ids=[183575], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='84', resumed_from_preemption=false, new_token_ids=[1542], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='85', resumed_from_preemption=false, new_token_ids=[237254], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='86', resumed_from_preemption=false, new_token_ids=[144120], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='87', resumed_from_preemption=false, new_token_ids=[1], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='88', resumed_from_preemption=false, new_token_ids=[495], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='89', resumed_from_preemption=false, new_token_ids=[239609], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='90', resumed_from_preemption=false, new_token_ids=[236889], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='91', resumed_from_preemption=false, new_token_ids=[594], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='92', resumed_from_preemption=false, new_token_ids=[727], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='93', resumed_from_preemption=false, new_token_ids=[2194], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='94', resumed_from_preemption=false, new_token_ids=[1849], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='95', resumed_from_preemption=false, new_token_ids=[121387], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1029), CachedRequestData(req_id='96', resumed_from_preemption=false, new_token_ids=[1875], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='97', resumed_from_preemption=false, new_token_ids=[236765], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='98', resumed_from_preemption=false, new_token_ids=[107], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='99', resumed_from_preemption=false, new_token_ids=[499], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='100', resumed_from_preemption=false, new_token_ids=[155702], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='101', resumed_from_preemption=false, new_token_ids=[37010], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='102', resumed_from_preemption=false, new_token_ids=[6625], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='103', resumed_from_preemption=false, new_token_ids=[59713], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='104', resumed_from_preemption=false, new_token_ids=[15670], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='105', resumed_from_preemption=false, new_token_ids=[67785], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='106', resumed_from_preemption=false, new_token_ids=[237697], new_block_ids=[[80025], [80026], [80027], [80028], [80029], [80030], [80031]], num_computed_tokens=1024), CachedRequestData(req_id='107', resumed_from_preemption=false, new_token_ids=[107], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='108', resumed_from_preemption=false, new_token_ids=[1211], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='109', resumed_from_preemption=false, new_token_ids=[238555], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='110', resumed_from_preemption=false, new_token_ids=[236803], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='111', resumed_from_preemption=false, new_token_ids=[3723], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1028), CachedRequestData(req_id='112', resumed_from_preemption=false, new_token_ids=[108573], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='113', resumed_from_preemption=false, new_token_ids=[29655], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='114', resumed_from_preemption=false, new_token_ids=[106], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='115', resumed_from_preemption=false, new_token_ids=[1992], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='116', resumed_from_preemption=false, new_token_ids=[1711], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='117', resumed_from_preemption=false, new_token_ids=[3552], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='118', resumed_from_preemption=false, new_token_ids=[106], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=746), CachedRequestData(req_id='119', resumed_from_preemption=false, new_token_ids=[733], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='120', resumed_from_preemption=false, new_token_ids=[3236], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='121', resumed_from_preemption=false, new_token_ids=[236762], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='122', resumed_from_preemption=false, new_token_ids=[237499], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='123', resumed_from_preemption=false, new_token_ids=[236774], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='124', resumed_from_preemption=false, new_token_ids=[236747], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='125', resumed_from_preemption=false, new_token_ids=[134819], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='126', resumed_from_preemption=false, new_token_ids=[236848], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='127', resumed_from_preemption=false, new_token_ids=[236800], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1027), CachedRequestData(req_id='128', resumed_from_preemption=false, new_token_ids=[239720], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='129', resumed_from_preemption=false, new_token_ids=[1148], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='130', resumed_from_preemption=false, new_token_ids=[188785], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='131', resumed_from_preemption=false, new_token_ids=[1721], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='132', resumed_from_preemption=false, new_token_ids=[819], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='133', resumed_from_preemption=false, new_token_ids=[3373], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='134', resumed_from_preemption=false, new_token_ids=[4460], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='135', resumed_from_preemption=false, new_token_ids=[8584], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='136', resumed_from_preemption=false, new_token_ids=[236743], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='137', resumed_from_preemption=false, new_token_ids=[243826], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='138', resumed_from_preemption=false, new_token_ids=[237640], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='139', resumed_from_preemption=false, new_token_ids=[505], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=745), CachedRequestData(req_id='140', resumed_from_preemption=false, new_token_ids=[187601], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='141', resumed_from_preemption=false, new_token_ids=[35614], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='142', resumed_from_preemption=false, new_token_ids=[236775], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='143', resumed_from_preemption=false, new_token_ids=[229450], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1026), CachedRequestData(req_id='144', resumed_from_preemption=false, new_token_ids=[8692], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='145', resumed_from_preemption=false, new_token_ids=[240303], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='146', resumed_from_preemption=false, new_token_ids=[34827], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='147', resumed_from_preemption=false, new_token_ids=[645], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='148', resumed_from_preemption=false, new_token_ids=[107], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='149', resumed_from_preemption=false, new_token_ids=[1688], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='150', resumed_from_preemption=false, new_token_ids=[241102], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='151', resumed_from_preemption=false, new_token_ids=[381], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='152', resumed_from_preemption=false, new_token_ids=[54955], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='153', resumed_from_preemption=false, new_token_ids=[68207], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='154', resumed_from_preemption=false, new_token_ids=[2387], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='155', resumed_from_preemption=false, new_token_ids=[40516], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='156', resumed_from_preemption=false, new_token_ids=[203623], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='157', resumed_from_preemption=false, new_token_ids=[236835], new_block_ids=[[80032], [80033], [80034], [80035], [80036], [80037], [80038]], num_computed_tokens=1024), CachedRequestData(req_id='158', resumed_from_preemption=false, new_token_ids=[239636], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='159', resumed_from_preemption=false, new_token_ids=[722], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1025), CachedRequestData(req_id='160', resumed_from_preemption=false, new_token_ids=[28897], new_block_ids=[[80039], [80040], [80041], [80042], [80043], [80044], [80045]], num_computed_tokens=1024), CachedRequestData(req_id='161', resumed_from_preemption=false, new_token_ids=[14851], new_block_ids=[[80046], [80047], [80048], [80049], [80050], [80051], [80052]], num_computed_tokens=1024), CachedRequestData(req_id='162', resumed_from_preemption=false, new_token_ids=[236894], new_block_ids=[[80053], [80054], [80055], [80056], [80057], [80058], [80059]], num_computed_tokens=1024), CachedRequestData(req_id='163', resumed_from_preemption=false, new_token_ids=[12585], new_block_ids=[[80060], [80061], [80062], [80063], [80064], [80065], [80066]], num_computed_tokens=1024), CachedRequestData(req_id='164', resumed_from_preemption=false, new_token_ids=[21294], new_block_ids=[[80067], [80068], [80069], [80070], [80071], [80072], [80073]], num_computed_tokens=1024), CachedRequestData(req_id='165', resumed_from_preemption=false, new_token_ids=[475], new_block_ids=[[80074], [80075], [80076], [80077], [80078], [80079], [80080]], num_computed_tokens=1024), CachedRequestData(req_id='166', resumed_from_preemption=false, new_token_ids=[236743], new_block_ids=[[80081], [80082], [80083], [80084], [80085], [80086], [80087]], num_computed_tokens=1024), CachedRequestData(req_id='167', resumed_from_preemption=false, new_token_ids=[239853], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1022), CachedRequestData(req_id='168', resumed_from_preemption=false, new_token_ids=[533], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=743), CachedRequestData(req_id='169', resumed_from_preemption=false, new_token_ids=[236799], new_block_ids=[[80088], [80089], [80090], [80091], [80092], [80093], [80094]], num_computed_tokens=1024), CachedRequestData(req_id='170', resumed_from_preemption=false, new_token_ids=[236747], new_block_ids=[[80095], [80096], [80097], [80098], [80099], [80100], [80101]], num_computed_tokens=1024), CachedRequestData(req_id='171', resumed_from_preemption=false, new_token_ids=[236743], new_block_ids=[[80102], [80103], [80104], [80105], [80106], [80107], [80108]], num_computed_tokens=1024), CachedRequestData(req_id='172', resumed_from_preemption=false, new_token_ids=[236821], new_block_ids=[[80109], [80110], [80111], [80112], [80113], [80114], [80115]], num_computed_tokens=1024), CachedRequestData(req_id='173', resumed_from_preemption=false, new_token_ids=[83803], new_block_ids=[[], [], [], [], [], [], []], num_computed_tokens=1009), CachedRequestData(req_id='174', resumed_from_preemption=false, new_token_ids=[163662], new_block_ids=[[80116], [80117], [80118], [80119], [80120], [80121], [80122]], num_computed_tokens=1024), CachedRequestData(req_id='175', resumed_from_preemption=false, new_token_ids=[245844], new_block_ids=[[80123], [80124], [80125], [80126], [80127], [80128], [80129]], num_computed_tokens=1024), CachedRequestData(req_id='176', resumed_from_preemption=false, new_token_ids=[88870, 88871, 88872, 88873, 88874, 88875, 88876, 88877, 88878, 88879, 88880, 88881, 88882, 88883, 88884, 88885], new_block_ids=[[80130], [80131], [80132], [80133], [80134], [80135], [80136]], num_computed_tokens=1008)], num_scheduled_tokens={130: 1, 168: 1, 181: 1024, 43: 1, 73: 1, 89: 1, 92: 1, 118: 1, 123: 1, 102: 1, 1: 1, 146: 1, 78: 1, 79: 1, 50: 1, 81: 1, 178: 1024, 85: 1, 23: 1, 180: 1024, 49: 1, 25: 1, 59: 1, 44: 1, 187: 1024, 31: 1, 47: 1, 55: 1, 86: 1, 39: 1, 72: 1, 75: 1, 84: 1, 188: 1024, 58: 1, 94: 1, 61: 1, 65: 1, 107: 1, 155: 1, 150: 1, 16: 1, 112: 1, 111: 1, 9: 1, 64: 1, 158: 1, 93: 1, 142: 1, 100: 1, 147: 1, 154: 1, 5: 1, 22: 1, 110: 1, 126: 1, 14: 1, 108: 1, 176: 16, 140: 1, 68: 1, 33: 1, 166: 1, 36: 1, 173: 1, 161: 1, 113: 1, 87: 1, 190: 1024, 164: 1, 67: 1, 171: 1, 82: 1, 120: 1, 133: 1, 129: 1, 117: 1, 83: 1, 143: 1, 185: 1024, 51: 1, 54: 1, 152: 1, 18: 1, 105: 1, 74: 1, 138: 1, 19: 1, 77: 1, 135: 1, 41: 1, 91: 1, 60: 1, 148: 1, 38: 1, 174: 1, 11: 1, 144: 1, 66: 1, 159: 1, 34: 1, 7: 1, 96: 1, 29: 1, 10: 1, 153: 1, 15: 1, 145: 1, 104: 1, 97: 1, 122: 1, 160: 1, 56: 1, 40: 1, 57: 1, 76: 1, 0: 1, 182: 1024, 46: 1, 172: 1, 109: 1, 167: 1, 21: 1, 184: 1024, 24: 1, 132: 1, 137: 1, 157: 1, 90: 1, 4: 1, 121: 1, 71: 1, 165: 1, 62: 1, 179: 1024, 106: 1, 48: 1, 151: 1, 115: 1, 191: 1024, 134: 1, 170: 1, 175: 1, 95: 1, 35: 1, 45: 1, 139: 1, 101: 1, 32: 1, 70: 1, 17: 1, 124: 1, 3: 1, 6: 1, 37: 1, 189: 1024, 20: 1, 116: 1, 53: 1, 149: 1, 28: 1, 80: 1, 114: 1, 131: 1, 52: 1, 169: 1, 177: 1024, 12: 1, 128: 1, 42: 1, 156: 1, 119: 1, 125: 1, 127: 1, 183: 1024, 69: 1, 192: 832, 99: 1, 88: 1, 136: 1, 163: 1, 8: 1, 27: 1, 13: 1, 186: 1024, 26: 1, 63: 1, 162: 1, 2: 1, 103: 1, 30: 1, 98: 1, 141: 1}, total_num_scheduled_tokens=16384, scheduled_spec_decode_tokens={}, scheduled_encoder_inputs={}, num_common_prefix_blocks=[0, 0, 0, 0, 0, 0, 0], finished_req_ids=[], free_encoder_input_ids=[], structured_output_request_ids={}, grammar_bitmask=null, kv_connector_metadata=null)
ERROR 06-25 15:33:59 [dump_input.py:82] SchedulerStats(num_running_reqs=193, num_waiting_reqs=7, gpu_cache_usage=0.3957234051241102, prefix_cache_stats=PrefixCacheStats(reset=False, requests=16, queries=16384, hits=0), spec_decoding_stats=None)

--- STDERR ---
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[1;36m(VllmWorker rank=1 pid=87801)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/12 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:   8% Completed | 1/12 [00:00<00:01,  9.63it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:  17% Completed | 2/12 [00:00<00:05,  1.97it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:  25% Completed | 3/12 [00:01<00:05,  1.58it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:  33% Completed | 4/12 [00:02<00:05,  1.45it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:  42% Completed | 5/12 [00:03<00:04,  1.40it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:  50% Completed | 6/12 [00:03<00:04,  1.38it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:  58% Completed | 7/12 [00:04<00:03,  1.49it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:  67% Completed | 8/12 [00:05<00:02,  1.44it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:  75% Completed | 9/12 [00:05<00:02,  1.42it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:  83% Completed | 10/12 [00:06<00:01,  1.40it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards:  92% Completed | 11/12 [00:07<00:00,  1.40it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards: 100% Completed | 12/12 [00:08<00:00,  1.40it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m Loading safetensors checkpoint shards: 100% Completed | 12/12 [00:08<00:00,  1.47it/s]
[1;36m(VllmWorker rank=0 pid=87800)[0;0m 
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Adding requests:   0%|          | 0/200 [00:00<?, ?it/s]Adding requests:  18%|█▊        | 35/200 [00:00<00:00, 340.95it/s]Adding requests:  38%|███▊      | 75/200 [00:00<00:00, 374.79it/s]Adding requests:  58%|█████▊    | 117/200 [00:00<00:00, 391.50it/s]Adding requests:  80%|████████  | 160/200 [00:00<00:00, 404.56it/s]Adding requests: 100%|██████████| 200/200 [00:00<00:00, 404.37it/s]
Processed prompts:   0%|          | 0/200 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Traceback (most recent call last):
  File "/home/pirillo_google_com/vllm_benchmark/vllm-repo-benchmark/benchmarks/benchmark_throughput.py", line 724, in <module>
    main(args)
  File "/home/pirillo_google_com/vllm_benchmark/vllm-repo-benchmark/benchmarks/benchmark_throughput.py", line 407, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/home/pirillo_google_com/vllm_benchmark/vllm-repo-benchmark/benchmarks/benchmark_throughput.py", line 92, in run_vllm
    outputs = llm.generate(
              ^^^^^^^^^^^^^
  File "/home/pirillo_google_com/.vllm/lib/python3.12/site-packages/vllm/utils.py", line 1267, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/pirillo_google_com/.vllm/lib/python3.12/site-packages/vllm/entrypoints/llm.py", line 474, in generate
    outputs = self._run_engine(use_tqdm=use_tqdm)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pirillo_google_com/.vllm/lib/python3.12/site-packages/vllm/entrypoints/llm.py", line 1517, in _run_engine
    step_outputs = self.llm_engine.step()
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pirillo_google_com/.vllm/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py", line 236, in step
    processed_outputs = self.output_processor.process_outputs(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pirillo_google_com/.vllm/lib/python3.12/site-packages/vllm/v1/engine/output_processor.py", line 351, in process_outputs
    stop_string = req_state.detokenizer.update(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pirillo_google_com/.vllm/lib/python3.12/site-packages/vllm/v1/engine/detokenizer.py", line 107, in update
    self.output_text += self.decode_next(new_token_id)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pirillo_google_com/.vllm/lib/python3.12/site-packages/vllm/v1/engine/detokenizer.py", line 202, in decode_next
    token = self.stream.step(self.tokenizer, next_token_id)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception: Invalid prefix encountered
[rank1]:[W625 15:34:00.634765312 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=186, addr=[localhost]:58734, remote=[localhost]:42939): failed to recv, got 0 bytes
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:678 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7d889f9785e8 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8afe (0x7d88835a8afe in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baae40 (0x7d88835aae40 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5bab74a (0x7d88835ab74a in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x2a9 (0x7d88835a51a9 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7d882f0f3989 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xecdb4 (0x7d881f0ecdb4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7d88a089caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c3c (0x7d88a0929c3c in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W625 15:34:00.637649540 ProcessGroupNCCL.cpp:1659] [PG ID 0 PG GUID 0 Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: failed to recv, got 0 bytes
[rank1]:[W625 15:34:01.637785633 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=186, addr=[localhost]:58734, remote=[localhost]:42939): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7d889f9785e8 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8afe (0x7d88835a8afe in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa358 (0x7d88835aa358 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babb3e (0x7d88835abb3e in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7d88835a5198 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7d882f0f3989 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xecdb4 (0x7d881f0ecdb4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7d88a089caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c3c (0x7d88a0929c3c in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W625 15:34:01.640567237 ProcessGroupNCCL.cpp:1659] [PG ID 0 PG GUID 0 Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank1]:[W625 15:34:02.640686634 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=186, addr=[localhost]:58734, remote=[localhost]:42939): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7d889f9785e8 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8afe (0x7d88835a8afe in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa358 (0x7d88835aa358 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babb3e (0x7d88835abb3e in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7d88835a5198 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7d882f0f3989 in /home/pirillo_google_com/.vllm/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xecdb4 (0x7d881f0ecdb4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7d88a089caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c3c (0x7d88a0929c3c in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W625 15:34:02.644388245 ProcessGroupNCCL.cpp:1659] [PG ID 0 PG GUID 0 Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Processed prompts:   0%|          | 0/200 [00:09<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
