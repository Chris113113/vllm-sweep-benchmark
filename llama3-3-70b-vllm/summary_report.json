[
    {
        "run_name": "Llama-3-3-70B_TP-1_ISL-128_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "1",
            "input-len": "128",
            "output-len": "1000",
            "max-model-len": "1128"
        },
        "results": {
            "throughput_req_per_sec": 1.95,
            "throughput_total_tokens_per_sec": 2195.46,
            "throughput_output_tokens_per_sec": 1946.33,
            "total_prompt_tokens": 12800,
            "total_output_tokens": 100000
        },
        "status": "SUCCESS",
        "client_log_file": "1_Llama-3-3-70B_TP-1_ISL-128_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-2_ISL-128_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "2",
            "input-len": "128",
            "output-len": "1000",
            "max-model-len": "1128"
        },
        "results": {
            "throughput_req_per_sec": 3.77,
            "throughput_total_tokens_per_sec": 4247.26,
            "throughput_output_tokens_per_sec": 3765.43,
            "total_prompt_tokens": 12796,
            "total_output_tokens": 100000
        },
        "status": "SUCCESS",
        "client_log_file": "2_Llama-3-3-70B_TP-2_ISL-128_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-4_ISL-128_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "4",
            "input-len": "128",
            "output-len": "1000",
            "max-model-len": "1128"
        },
        "results": {
            "throughput_req_per_sec": 4.76,
            "throughput_total_tokens_per_sec": 5363.21,
            "throughput_output_tokens_per_sec": 4757.32,
            "total_prompt_tokens": 12736,
            "total_output_tokens": 100000
        },
        "status": "SUCCESS",
        "client_log_file": "3_Llama-3-3-70B_TP-4_ISL-128_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-128_OSL-1000",
        "status": "TERMINATED_DUE_TO_ERROR"
    },
    {
        "run_name": "Llama-3-3-70B_TP-1_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "1",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 8.57,
            "throughput_total_tokens_per_sec": 4386.23,
            "throughput_output_tokens_per_sec": 2193.12,
            "total_prompt_tokens": 25600,
            "total_output_tokens": 25600
        },
        "status": "SUCCESS",
        "client_log_file": "5_Llama-3-3-70B_TP-1_ISL-256_OSL-256_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-2_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "2",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 12.68,
            "throughput_total_tokens_per_sec": 6490.88,
            "throughput_output_tokens_per_sec": 3245.63,
            "total_prompt_tokens": 25597,
            "total_output_tokens": 25600
        },
        "status": "SUCCESS",
        "client_log_file": "6_Llama-3-3-70B_TP-2_ISL-256_OSL-256_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-4_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "4",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 16.83,
            "throughput_total_tokens_per_sec": 8618.26,
            "throughput_output_tokens_per_sec": 4309.3,
            "total_prompt_tokens": 25598,
            "total_output_tokens": 25600
        },
        "status": "SUCCESS",
        "client_log_file": "7_Llama-3-3-70B_TP-4_ISL-256_OSL-256_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-256_OSL-256",
        "status": "TERMINATED_DUE_TO_ERROR"
    },
    {
        "run_name": "Llama-3-3-70B_TP-1_ISL-1000_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "1",
            "input-len": "1000",
            "output-len": "1000",
            "max-model-len": "2000"
        },
        "results": {
            "throughput_req_per_sec": 1.06,
            "throughput_total_tokens_per_sec": 2111.69,
            "throughput_output_tokens_per_sec": 1056.77,
            "total_prompt_tokens": 99825,
            "total_output_tokens": 100000
        },
        "status": "SUCCESS",
        "client_log_file": "9_Llama-3-3-70B_TP-1_ISL-1000_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-2_ISL-1000_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "2",
            "input-len": "1000",
            "output-len": "1000",
            "max-model-len": "2000"
        },
        "results": {
            "throughput_req_per_sec": 2.79,
            "throughput_total_tokens_per_sec": 5579.72,
            "throughput_output_tokens_per_sec": 2790.73,
            "total_prompt_tokens": 99938,
            "total_output_tokens": 100000
        },
        "status": "SUCCESS",
        "client_log_file": "10_Llama-3-3-70B_TP-2_ISL-1000_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-4_ISL-1000_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "4",
            "input-len": "1000",
            "output-len": "1000",
            "max-model-len": "2000"
        },
        "results": {
            "throughput_req_per_sec": 3.83,
            "throughput_total_tokens_per_sec": 7665.13,
            "throughput_output_tokens_per_sec": 3834.98,
            "total_prompt_tokens": 99874,
            "total_output_tokens": 100000
        },
        "status": "SUCCESS",
        "client_log_file": "11_Llama-3-3-70B_TP-4_ISL-1000_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-1000_OSL-1000",
        "status": "TERMINATED_DUE_TO_ERROR"
    },
    {
        "run_name": "Llama-3-3-70B_TP-1_ISL-5000_OSL-5000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "1",
            "input-len": "5000",
            "output-len": "5000",
            "max-model-len": "10000"
        },
        "results": {},
        "client_log_file": "13_Llama-3-3-70B_TP-1_ISL-5000_OSL-5000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-2_ISL-5000_OSL-5000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "2",
            "input-len": "5000",
            "output-len": "5000",
            "max-model-len": "10000"
        },
        "results": {},
        "client_log_file": "14_Llama-3-3-70B_TP-2_ISL-5000_OSL-5000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-4_ISL-5000_OSL-5000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "4",
            "input-len": "5000",
            "output-len": "5000",
            "max-model-len": "10000"
        },
        "results": {},
        "client_log_file": "15_Llama-3-3-70B_TP-4_ISL-5000_OSL-5000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-5000_OSL-5000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "8",
            "input-len": "5000",
            "output-len": "5000",
            "max-model-len": "10000"
        },
        "results": {},
        "client_log_file": "16_Llama-3-3-70B_TP-8_ISL-5000_OSL-5000_vllm_script.log"
    }
]