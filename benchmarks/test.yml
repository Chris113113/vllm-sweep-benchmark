standalone_runs:
  # ==============================================================================
  # Llama-3.3-70B-Instruct
  # ==============================================================================
  - name: "Llama-3.1-8B-Instruct"
    mode: "vllm_throughput"
    tensor_parallel_sizes: [1, 2, 4, 8]
    length_configs:
      - { input_len: 1024, output_len: 256 }
      - { input_len: 1024, output_len: 1024 }
      - { input_len: 1024, output_len: 4096 }
      - { input_len: 2048, output_len: 8192 }
    args: >
      --model "meta-llama/Llama-3.1-8B-Instruct"
      --num-prompts 10000
      --gpu-memory-utilization 0.9
      --quantization fp8
      --dtype auto