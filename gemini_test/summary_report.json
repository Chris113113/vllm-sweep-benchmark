[
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-128_OSL-1000",
        "status": "TERMINATED_DUE_TO_FATAL_ERROR"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "10",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "8",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 2.78,
            "throughput_total_tokens_per_sec": 1421.54,
            "throughput_output_tokens_per_sec": 710.77,
            "total_prompt_tokens": 2560,
            "total_output_tokens": 2560
        },
        "client_log_file": "2_Llama-3-3-70B_TP-8_ISL-256_OSL-256_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-1000_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "10",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "8",
            "input-len": "1000",
            "output-len": "1000",
            "max-model-len": "2000"
        },
        "results": {
            "throughput_req_per_sec": 0.72,
            "throughput_total_tokens_per_sec": 1440.38,
            "throughput_output_tokens_per_sec": 720.19,
            "total_prompt_tokens": 10000,
            "total_output_tokens": 10000
        },
        "client_log_file": "3_Llama-3-3-70B_TP-8_ISL-1000_OSL-1000_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-5000_OSL-5000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "10",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "8",
            "input-len": "5000",
            "output-len": "5000",
            "max-model-len": "10000"
        },
        "results": {
            "throughput_req_per_sec": 0.14,
            "throughput_total_tokens_per_sec": 1389.88,
            "throughput_output_tokens_per_sec": 694.94,
            "total_prompt_tokens": 50000,
            "total_output_tokens": 50000
        },
        "client_log_file": "4_Llama-3-3-70B_TP-8_ISL-5000_OSL-5000_vllm_script.log",
        "status": "SUCCESS"
    }
]