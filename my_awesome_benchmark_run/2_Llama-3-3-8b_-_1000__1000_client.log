--- Client Run: Llama-3-3-8b - 1000 / 1000 ---

--- Client STDOUT ---
{
  "config": {
    "model": "meta-llama/Llama-3.3-70B-Instruct",
    "num_prompts": 100,
    "concurrency": 125,
    "max_input_length": 1000,
    "max_output_length": 1000
  },
  "results": {
    "total_duration_sec": 26.97,
    "successful_requests": 100,
    "failed_requests": 0,
    "total_tokens_generated": 75551,
    "throughput_req_per_sec": 3.71,
    "throughput_tokens_per_sec": 2801.26,
    "effective_avg_latency_ms": 33713.01,
    "errors": []
  }
}

--- Client STDERR ---
Client: Starting benchmark with a constant concurrency of 125...
Client: Loading dataset and populating queue...
Client: Completed 20/100 requests...
Client: Completed 40/100 requests...
Client: Completed 60/100 requests...
Client: Completed 80/100 requests...
Client: Completed 100/100 requests...

================================================================================
Client Benchmark Summary
================================================================================
Total Time Taken: 26.97 seconds
Total Requests Sent: 100
Successful Requests: 100
Failed Requests: 0

--- Performance ---
Throughput (Requests/sec): 3.71
Throughput (Tokens/sec): 2801.26
Effective Avg Latency (per request): 33713.01 ms
================================================================================
