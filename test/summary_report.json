[
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-128_OSL-1000",
        "status": "TERMINATED_DUE_TO_ERROR"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-256_OSL-256",
        "status": "TERMINATED_DUE_TO_ERROR"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-1000_OSL-1000",
        "status": "TERMINATED_DUE_TO_ERROR"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-5000_OSL-5000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "10",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "8",
            "input-len": "5000",
            "output-len": "5000",
            "max-model-len": "10000"
        },
        "results": {
            "throughput_req_per_sec": 0.14,
            "throughput_total_tokens_per_sec": 1364.0,
            "throughput_output_tokens_per_sec": 682.12,
            "total_prompt_tokens": 49983,
            "total_output_tokens": 50000
        },
        "client_log_file": "4_Llama-3-3-70B_TP-8_ISL-5000_OSL-5000_vllm_script.log",
        "status": "SUCCESS"
    }
]