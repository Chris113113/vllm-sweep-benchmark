[
    {
        "run_name": "Llama-3.3-70B-Instruct_TP-2_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "2",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 21.8,
            "throughput_total_tokens_per_sec": 11157.95,
            "throughput_output_tokens_per_sec": 5581.32,
            "total_prompt_tokens": 51157,
            "total_output_tokens": 51200
        },
        "client_log_file": "1_Llama-3.3-70B-Instruct_TP-2_ISL-256_OSL-256_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.3-70B-Instruct_TP-4_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "4",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 27.88,
            "throughput_total_tokens_per_sec": 14274.24,
            "throughput_output_tokens_per_sec": 7137.33,
            "total_prompt_tokens": 51197,
            "total_output_tokens": 51200
        },
        "client_log_file": "2_Llama-3.3-70B-Instruct_TP-4_ISL-256_OSL-256_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.3-70B-Instruct_TP-8_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "8",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 31.76,
            "throughput_total_tokens_per_sec": 16263.68,
            "throughput_output_tokens_per_sec": 8131.84,
            "total_prompt_tokens": 51200,
            "total_output_tokens": 51200
        },
        "client_log_file": "3_Llama-3.3-70B-Instruct_TP-8_ISL-256_OSL-256_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.3-70B-Instruct_TP-2_ISL-1024_OSL-1024",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "2",
            "input-len": "1024",
            "output-len": "1024",
            "max-model-len": "2048"
        },
        "results": {
            "throughput_req_per_sec": 4.69,
            "throughput_total_tokens_per_sec": 9591.32,
            "throughput_output_tokens_per_sec": 4802.48,
            "total_prompt_tokens": 204218,
            "total_output_tokens": 204800
        },
        "client_log_file": "4_Llama-3.3-70B-Instruct_TP-2_ISL-1024_OSL-1024_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.3-70B-Instruct_TP-4_ISL-1024_OSL-1024",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "4",
            "input-len": "1024",
            "output-len": "1024",
            "max-model-len": "2048"
        },
        "results": {
            "throughput_req_per_sec": 6.23,
            "throughput_total_tokens_per_sec": 12767.64,
            "throughput_output_tokens_per_sec": 6383.82,
            "total_prompt_tokens": 204800,
            "total_output_tokens": 204800
        },
        "client_log_file": "5_Llama-3.3-70B-Instruct_TP-4_ISL-1024_OSL-1024_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.3-70B-Instruct_TP-8_ISL-1024_OSL-1024",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "8",
            "input-len": "1024",
            "output-len": "1024",
            "max-model-len": "2048"
        },
        "results": {
            "throughput_req_per_sec": 7.34,
            "throughput_total_tokens_per_sec": 15017.75,
            "throughput_output_tokens_per_sec": 7515.55,
            "total_prompt_tokens": 204436,
            "total_output_tokens": 204800
        },
        "client_log_file": "6_Llama-3.3-70B-Instruct_TP-8_ISL-1024_OSL-1024_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.3-70B-Instruct_TP-2_ISL-4096_OSL-4096",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "2",
            "input-len": "4096",
            "output-len": "4096",
            "max-model-len": "8192"
        },
        "results": {
            "throughput_req_per_sec": 0.52,
            "throughput_total_tokens_per_sec": 4257.77,
            "throughput_output_tokens_per_sec": 2129.18,
            "total_prompt_tokens": 818975,
            "total_output_tokens": 819200
        },
        "client_log_file": "7_Llama-3.3-70B-Instruct_TP-2_ISL-4096_OSL-4096_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.3-70B-Instruct_TP-4_ISL-4096_OSL-4096",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "4",
            "input-len": "4096",
            "output-len": "4096",
            "max-model-len": "8192"
        },
        "results": {
            "throughput_req_per_sec": 1.08,
            "throughput_total_tokens_per_sec": 8818.48,
            "throughput_output_tokens_per_sec": 4409.85,
            "total_prompt_tokens": 818972,
            "total_output_tokens": 819200
        },
        "client_log_file": "8_Llama-3.3-70B-Instruct_TP-4_ISL-4096_OSL-4096_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.3-70B-Instruct_TP-8_ISL-4096_OSL-4096",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "8",
            "input-len": "4096",
            "output-len": "4096",
            "max-model-len": "8192"
        },
        "results": {
            "throughput_req_per_sec": 1.44,
            "throughput_total_tokens_per_sec": 11833.11,
            "throughput_output_tokens_per_sec": 5917.33,
            "total_prompt_tokens": 818985,
            "total_output_tokens": 819200
        },
        "client_log_file": "9_Llama-3.3-70B-Instruct_TP-8_ISL-4096_OSL-4096_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.1-8B-Instruct_TP-1_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.1-8B-Instruct",
            "num-prompts": "500",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "1",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 78.14,
            "throughput_total_tokens_per_sec": 39968.6,
            "throughput_output_tokens_per_sec": 20003.36,
            "total_prompt_tokens": 127756,
            "total_output_tokens": 128000
        },
        "client_log_file": "10_Llama-3.1-8B-Instruct_TP-1_ISL-256_OSL-256_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.1-8B-Instruct_TP-2_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.1-8B-Instruct",
            "num-prompts": "500",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "2",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 91.23,
            "throughput_total_tokens_per_sec": 46646.89,
            "throughput_output_tokens_per_sec": 23355.56,
            "total_prompt_tokens": 127648,
            "total_output_tokens": 128000
        },
        "client_log_file": "11_Llama-3.1-8B-Instruct_TP-2_ISL-256_OSL-256_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.1-8B-Instruct_TP-1_ISL-1024_OSL-1024",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.1-8B-Instruct",
            "num-prompts": "500",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "1",
            "input-len": "1024",
            "output-len": "1024",
            "max-model-len": "2048"
        },
        "results": {
            "throughput_req_per_sec": 10.29,
            "throughput_total_tokens_per_sec": 21060.26,
            "throughput_output_tokens_per_sec": 10533.49,
            "total_prompt_tokens": 511674,
            "total_output_tokens": 512000
        },
        "client_log_file": "12_Llama-3.1-8B-Instruct_TP-1_ISL-1024_OSL-1024_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.1-8B-Instruct_TP-2_ISL-1024_OSL-1024",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.1-8B-Instruct",
            "num-prompts": "500",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "2",
            "input-len": "1024",
            "output-len": "1024",
            "max-model-len": "2048"
        },
        "results": {
            "throughput_req_per_sec": 14.4,
            "throughput_total_tokens_per_sec": 29484.59,
            "throughput_output_tokens_per_sec": 14747.31,
            "total_prompt_tokens": 511652,
            "total_output_tokens": 512000
        },
        "client_log_file": "13_Llama-3.1-8B-Instruct_TP-2_ISL-1024_OSL-1024_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.1-8B-Instruct_TP-1_ISL-4096_OSL-4096",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.1-8B-Instruct",
            "num-prompts": "500",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "1",
            "input-len": "4096",
            "output-len": "4096",
            "max-model-len": "8192"
        },
        "results": {
            "throughput_req_per_sec": 0.71,
            "throughput_total_tokens_per_sec": 5830.67,
            "throughput_output_tokens_per_sec": 2915.66,
            "total_prompt_tokens": 2047544,
            "total_output_tokens": 2048000
        },
        "client_log_file": "14_Llama-3.1-8B-Instruct_TP-1_ISL-4096_OSL-4096_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Llama-3.1-8B-Instruct_TP-2_ISL-4096_OSL-4096",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.1-8B-Instruct",
            "num-prompts": "500",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "2",
            "input-len": "4096",
            "output-len": "4096",
            "max-model-len": "8192"
        },
        "results": {
            "throughput_req_per_sec": 1.32,
            "throughput_total_tokens_per_sec": 10813.78,
            "throughput_output_tokens_per_sec": 5407.66,
            "total_prompt_tokens": 2047413,
            "total_output_tokens": 2048000
        },
        "client_log_file": "15_Llama-3.1-8B-Instruct_TP-2_ISL-4096_OSL-4096_vllm_script.log",
        "status": "SUCCESS"
    },
    {
        "run_name": "Gemma-3-27B-IT_TP-1_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "google/gemma-3-27b-it",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "1",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {},
        "client_log_file": "16_Gemma-3-27B-IT_TP-1_ISL-256_OSL-256_vllm_script.log",
        "status": "COMPLETED"
    },
    {
        "run_name": "Gemma-3-27B-IT_TP-2_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "google/gemma-3-27b-it",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "2",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {},
        "client_log_file": "17_Gemma-3-27B-IT_TP-2_ISL-256_OSL-256_vllm_script.log",
        "status": "COMPLETED"
    },
    {
        "run_name": "Gemma-3-27B-IT_TP-4_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "google/gemma-3-27b-it",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "4",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {},
        "client_log_file": "18_Gemma-3-27B-IT_TP-4_ISL-256_OSL-256_vllm_script.log",
        "status": "COMPLETED"
    },
    {
        "run_name": "Gemma-3-27B-IT_TP-1_ISL-1024_OSL-1024",
        "mode": "vllm_throughput",
        "config": {
            "model": "google/gemma-3-27b-it",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "1",
            "input-len": "1024",
            "output-len": "1024",
            "max-model-len": "2048"
        },
        "results": {},
        "client_log_file": "19_Gemma-3-27B-IT_TP-1_ISL-1024_OSL-1024_vllm_script.log",
        "status": "COMPLETED"
    },
    {
        "run_name": "Gemma-3-27B-IT_TP-2_ISL-1024_OSL-1024",
        "mode": "vllm_throughput",
        "config": {
            "model": "google/gemma-3-27b-it",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "2",
            "input-len": "1024",
            "output-len": "1024",
            "max-model-len": "2048"
        },
        "results": {},
        "client_log_file": "20_Gemma-3-27B-IT_TP-2_ISL-1024_OSL-1024_vllm_script.log",
        "status": "COMPLETED"
    },
    {
        "run_name": "Gemma-3-27B-IT_TP-4_ISL-1024_OSL-1024",
        "mode": "vllm_throughput",
        "config": {
            "model": "google/gemma-3-27b-it",
            "num-prompts": "200",
            "gpu-memory-utilization": "0.9",
            "quantization": "fp8",
            "tensor-parallel-size": "4",
            "input-len": "1024",
            "output-len": "1024",
            "max-model-len": "2048"
        },
        "results": {},
        "client_log_file": "21_Gemma-3-27B-IT_TP-4_ISL-1024_OSL-1024_vllm_script.log",
        "status": "COMPLETED"
    },
    {
        "run_name": "Gemma-3-27B-IT_TP-1_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Gemma-3-27B-IT_TP-2_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Gemma-3-27B-IT_TP-4_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-1_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-2_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-4_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-8_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-1_ISL-1024_OSL-1024",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-2_ISL-1024_OSL-1024",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-4_ISL-1024_OSL-1024",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-8_ISL-1024_OSL-1024",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-1_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-2_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-4_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-32B_TP-8_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-4B_TP-1_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-4B_TP-2_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-4B_TP-1_ISL-1024_OSL-1024",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-4B_TP-2_ISL-1024_OSL-1024",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-4B_TP-1_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Qwen3-4B_TP-2_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-1_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-2_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-4_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-8_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-1_ISL-1024_OSL-1024",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-2_ISL-1024_OSL-1024",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-4_ISL-1024_OSL-1024",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-8_ISL-1024_OSL-1024",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-1_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-2_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-4_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-4-Maverick-17B-128E-Instruct_TP-8_ISL-4096_OSL-4096",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "DeepSeek-R1-671B_TP-2_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "DeepSeek-R1-671B_TP-4_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "DeepSeek-R1-671B_TP-8_ISL-256_OSL-256",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "DeepSeek-R1-671B_TP-2_ISL-1000_OSL-1000",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "DeepSeek-R1-671B_TP-4_ISL-1000_OSL-1000",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "DeepSeek-R1-671B_TP-8_ISL-1000_OSL-1000",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-Guard-4-12B_TP-1_ISL-256_OSL-64",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-Guard-4-12B_TP-2_ISL-256_OSL-64",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-Guard-4-12B_TP-1_ISL-1024_OSL-64",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-Guard-4-12B_TP-2_ISL-1024_OSL-64",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-Guard-4-12B_TP-1_ISL-5000_OSL-64",
        "status": "NOT_STARTED"
    },
    {
        "run_name": "Llama-Guard-4-12B_TP-2_ISL-5000_OSL-64",
        "status": "NOT_STARTED"
    }
]