[
    {
        "run_name": "Llama-3-3-70B_TP-1_ISL-128_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "1",
            "input-len": "128",
            "output-len": "1000",
            "max-model-len": "1128"
        },
        "results": {
            "throughput_req_per_sec": 1.95,
            "throughput_total_tokens_per_sec": 2196.85,
            "throughput_output_tokens_per_sec": 1948.97,
            "total_prompt_tokens": 12719,
            "total_output_tokens": 100000
        },
        "client_log_file": "1_Llama-3-3-70B_TP-1_ISL-128_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-2_ISL-128_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "2",
            "input-len": "128",
            "output-len": "1000",
            "max-model-len": "1128"
        },
        "results": {
            "throughput_req_per_sec": 3.76,
            "throughput_total_tokens_per_sec": 4245.74,
            "throughput_output_tokens_per_sec": 3763.95,
            "total_prompt_tokens": 12800,
            "total_output_tokens": 100000
        },
        "client_log_file": "2_Llama-3-3-70B_TP-2_ISL-128_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-4_ISL-128_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "4",
            "input-len": "128",
            "output-len": "1000",
            "max-model-len": "1128"
        },
        "results": {
            "throughput_req_per_sec": 4.74,
            "throughput_total_tokens_per_sec": 5344.63,
            "throughput_output_tokens_per_sec": 4738.32,
            "total_prompt_tokens": 12796,
            "total_output_tokens": 100000
        },
        "client_log_file": "3_Llama-3-3-70B_TP-4_ISL-128_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-128_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "8",
            "input-len": "128",
            "output-len": "1000",
            "max-model-len": "1128"
        },
        "results": {
            "throughput_req_per_sec": 6.16,
            "throughput_total_tokens_per_sec": 6953.44,
            "throughput_output_tokens_per_sec": 6164.4,
            "total_prompt_tokens": 12800,
            "total_output_tokens": 100000
        },
        "client_log_file": "4_Llama-3-3-70B_TP-8_ISL-128_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-1_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "1",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 8.59,
            "throughput_total_tokens_per_sec": 4392.08,
            "throughput_output_tokens_per_sec": 2199.13,
            "total_prompt_tokens": 25528,
            "total_output_tokens": 25600
        },
        "client_log_file": "5_Llama-3-3-70B_TP-1_ISL-256_OSL-256_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-2_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "2",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 12.65,
            "throughput_total_tokens_per_sec": 6474.46,
            "throughput_output_tokens_per_sec": 3237.23,
            "total_prompt_tokens": 25600,
            "total_output_tokens": 25600
        },
        "client_log_file": "6_Llama-3-3-70B_TP-2_ISL-256_OSL-256_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-4_ISL-256_OSL-256",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "4",
            "input-len": "256",
            "output-len": "256",
            "max-model-len": "512"
        },
        "results": {
            "throughput_req_per_sec": 16.8,
            "throughput_total_tokens_per_sec": 8603.09,
            "throughput_output_tokens_per_sec": 4301.55,
            "total_prompt_tokens": 25600,
            "total_output_tokens": 25600
        },
        "client_log_file": "7_Llama-3-3-70B_TP-4_ISL-256_OSL-256_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-256_OSL-256",
        "status": "TERMINATED_DUE_TO_ERROR"
    },
    {
        "run_name": "Llama-3-3-70B_TP-1_ISL-1000_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "1",
            "input-len": "1000",
            "output-len": "1000",
            "max-model-len": "2000"
        },
        "results": {
            "throughput_req_per_sec": 1.06,
            "throughput_total_tokens_per_sec": 2123.95,
            "throughput_output_tokens_per_sec": 1062.49,
            "total_prompt_tokens": 99903,
            "total_output_tokens": 100000
        },
        "client_log_file": "9_Llama-3-3-70B_TP-1_ISL-1000_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-2_ISL-1000_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "2",
            "input-len": "1000",
            "output-len": "1000",
            "max-model-len": "2000"
        },
        "results": {
            "throughput_req_per_sec": 2.79,
            "throughput_total_tokens_per_sec": 5578.91,
            "throughput_output_tokens_per_sec": 2790.12,
            "total_prompt_tokens": 99952,
            "total_output_tokens": 100000
        },
        "client_log_file": "10_Llama-3-3-70B_TP-2_ISL-1000_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-4_ISL-1000_OSL-1000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "4",
            "input-len": "1000",
            "output-len": "1000",
            "max-model-len": "2000"
        },
        "results": {
            "throughput_req_per_sec": 3.85,
            "throughput_total_tokens_per_sec": 7692.12,
            "throughput_output_tokens_per_sec": 3846.06,
            "total_prompt_tokens": 100000,
            "total_output_tokens": 100000
        },
        "client_log_file": "11_Llama-3-3-70B_TP-4_ISL-1000_OSL-1000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-1000_OSL-1000",
        "status": "TERMINATED_DUE_TO_ERROR"
    },
    {
        "run_name": "Llama-3-3-70B_TP-1_ISL-5000_OSL-5000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "1",
            "input-len": "5000",
            "output-len": "5000",
            "max-model-len": "10000"
        },
        "results": {
            "throughput_req_per_sec": 0.05,
            "throughput_total_tokens_per_sec": 543.05,
            "throughput_output_tokens_per_sec": 271.54,
            "total_prompt_tokens": 499958,
            "total_output_tokens": 500000
        },
        "client_log_file": "13_Llama-3-3-70B_TP-1_ISL-5000_OSL-5000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-2_ISL-5000_OSL-5000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "2",
            "input-len": "5000",
            "output-len": "5000",
            "max-model-len": "10000"
        },
        "results": {
            "throughput_req_per_sec": 0.24,
            "throughput_total_tokens_per_sec": 2426.77,
            "throughput_output_tokens_per_sec": 1213.38,
            "total_prompt_tokens": 500000,
            "total_output_tokens": 500000
        },
        "client_log_file": "14_Llama-3-3-70B_TP-2_ISL-5000_OSL-5000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-4_ISL-5000_OSL-5000",
        "mode": "vllm_throughput",
        "config": {
            "model": "meta-llama/Llama-3.3-70B-Instruct",
            "num-prompts": "100",
            "gpu-memory-utilization": "0.9",
            "tensor-parallel-size": "4",
            "input-len": "5000",
            "output-len": "5000",
            "max-model-len": "10000"
        },
        "results": {
            "throughput_req_per_sec": 0.55,
            "throughput_total_tokens_per_sec": 5452.12,
            "throughput_output_tokens_per_sec": 2726.22,
            "total_prompt_tokens": 499942,
            "total_output_tokens": 500000
        },
        "client_log_file": "15_Llama-3-3-70B_TP-4_ISL-5000_OSL-5000_vllm_script.log"
    },
    {
        "run_name": "Llama-3-3-70B_TP-8_ISL-5000_OSL-5000",
        "status": "TERMINATED_DUE_TO_ERROR"
    }
]