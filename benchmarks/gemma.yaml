# ==============================================================================
# VLLM Automated Benchmark Configuration for Ironwood Workloads
# ==============================================================================
#
# This file defines a suite of standalone benchmark runs using the official
# vLLM benchmark script (benchmarks/benchmark_throughput.py), based on the
# workloads defined in DESIGN.md.
#
# Configurations are grouped by model and prefix length to reduce redundancy.

standalone_runs:
# ==============================================================================
  # Gemma-3-27B-IT
  # ==============================================================================
  # Flash-infer does not work on Gemma in current vLLM release, need to run separately.
  - name: "Gemma-3-27B-IT"
    mode: "vllm_throughput"
    tensor_parallel_sizes: [1]
    args: >
      --model "google/gemma-3-27b-it"
      --num-prompts 1000
      --gpu-memory-utilization 0.9
      --quantization fp8
      --dtype auto
    length_configs:
      - { input_len: 2048, output_len: 8192, prefix_len: 0 }
      - { input_len: 1024, output_len: 4096, prefix_len: 0 }
      - { input_len: 1024, output_len: 1024, prefix_len: 0 }
      - { input_len: 8192, output_len: 2048, prefix_len: 7900 }
      - { input_len: 2048, output_len: 256, prefix_len: 1800 }
      - { input_len: 4096, output_len: 256, prefix_len: 1800 }
